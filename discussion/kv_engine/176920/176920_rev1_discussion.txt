======================================================================================================================
DESCRIPTION:

Disconnect DCP connections when they loose privilege

Disconnect a DCP connection if the user don't have
any DCP privileges left:

    INFO 304: RBAC configuration updated [ {"ip":"127.0.0.1","port":32836} - {"ip":"127.0.0.1","port":11209} (System, <ud>@ns_server</ud>) ]
    INFO 74: RBAC: [ {"ip":"127.0.0.1","port":51552} - {"ip":"127.0.0.1","port":11210} (<ud>trond</ud>) ] No access to bucket [travel-sample]. New privilege set: [none]
    WARNING 74: Shutting down connection ([ {"ip":"127.0.0.1","port":51552} - {"ip":"127.0.0.1","port":11210} (<ud>trond</ud>) ]) as the DcpProducer privilege is lost

(followed by an insane amount of DCP logging from ep-engine)

Change-Id: I062256caa5d6ced3c26d814ef48a1ae99ed6ac9f

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Trond Norbye
Date: 2022-06-30 11:21:30.000000000
Message: 
Uploaded patch set 1.
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-06-30 11:33:07.000000000
Message: 
Patch Set 1: Code-Review-1

(1 comment)
Line:723, daemon/connection.cc -> Note ep-engine already checks this at every Snapshot marker; which means we ensure a DCP consumer has a consistent set of data before terminating them - see https://github.com/couchbase/kv_engine/blob/master/engines/ep/src/dcp/producer.cc#L1775

I think that it's (a) cleaner as we finish sending the snapshot in flight, and (b) more graceful from ep-engine's pov as it gets to clean things up.

What's the motivation for this change?

----------------------------------------------------------------------------------------------------------------------
Author: Trond Norbye
Date: 2022-06-30 11:48:57.000000000
Message: 
Patch Set 1:

(1 comment)
Line:723, daemon/connection.cc -> Manual test of deleting a user which is doing DCP drain. Ep engine didn't return back something which would cause us to disconnect as we ended up in an infinite loop trying to drain the system.

I don't think its cleaner to continue to send data when we detect that you no longer have access to the system...

----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2022-06-30 12:05:18.000000000
Message: 
Patch Set 1: Verified+1

Build Successful 

http://cv.jenkins.couchbase.com/job/kv_engine-clang_format_9/17600/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/47216/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_tidy-master/18449/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/39665/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/8122/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/19555/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/20334/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/20679/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/21320/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/28712/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/8221/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Trond Norbye
Date: 2022-07-01 05:14:31.000000000
MISMATCHED INLINE COMMENT
Line:723, daemon/connection.cc -> 1. I think we should cancel "immediately" when the operator removed all of our DCP access. The snapshot could be million of documents away. The privilege check in this patch is reduced to 1 time per time we want to refill the pipe (and not for each individual document being pushed into the pipe (until we back off to wait for the send queue to drain (or backing off to avoid starving the other connections bound to the same connection). That enforce the "no more than a handful documents" may be pushed at the same time.

2. I'll file a ticket for ep-engine to look up the termination reason as part of disconnect.
----------------------------------------------------------------------------------------------------------------------
Author: Trond Norbye
Date: 2022-07-01 06:06:02.000000000
MISMATCHED INLINE COMMENT
Line:723, daemon/connection.cc -> Actually, I think 2 _is_ already solved:

First we log:

    INFO 74: RBAC: [ {"ip":"127.0.0.1","port":51552} - {"ip":"127.0.0.1","port":11210} (<ud>trond</ud>) ] No access to bucket [travel-sample]. New privilege set: [none]

Followed by:

    WARNING 74: Shutting down connection ([ {"ip":"127.0.0.1","port":51552} - {"ip":"127.0.0.1","port":11210} (<ud>trond</ud>) ]) as the DcpProducer privilege is lost
    
And then EP engine start with:

    INFO 74: (No Engine) DCP (Producer) eq_dcpq:dcpdrain - Removing connection [ {"ip":"127.0.0.1","port":51552} - {"ip":"127.0.0.1","port":11210} (<ud>trond</ud>) ]
    
Followed by all of the lines where it was removed.
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-06-30 13:57:38.000000000
MISMATCHED INLINE COMMENT
Line:723, daemon/connection.cc -> So I think there's two issues here:

1. Do we cancel immediately or wait until the current "request" has comlpleted?

2. Do we propogate the correct reason why the streams were closed to the DcpProducer in ep-engine, or just pull the connection?

re: (1), What I'm suggesting is finishing the current snapshot as we do for loosing access to a collection. You might want to check with Jim why we did it that way; there might have been come concern about checking privs too often...

re: (2), Hopefully you agree we should set the status on the stream; that means the log etc will show sensible reasons for why Streams ended.
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-06-30 12:43:47.000000000
MISMATCHED INLINE COMMENT
Line:723, daemon/connection.cc -> I believe for standard request/resposne we complete the request if it was authorised when it started - including things like STAT commands which can have multiple responses.

For DCP, the analogy there would be to complete the Snapshot, which is typically only a few (single-digit) mutations as that allows the client to shutdown in a controlled manner (they don't need to rollback to the last consistent point).

As per the discussion on Slack, to allow DCP Streams inside ep-engine to log useful shutdown reasons, we really want to pass DcpStreamEndStatus::LostPrivileges as the stream end reason - see DcpProducer::setDisconnect(), we could look at passing a reason into that method.
----------------------------------------------------------------------------------------------------------------------
Author: Jim Walker
Date: 2022-08-16 12:55:24.000000000
MISMATCHED INLINE COMMENT
Line:723, daemon/connection.cc -> So the code we have in ep-engine is concerned with the checking of the DcpStream privilege - this is effectively a "Read" priv for a collection/scope/bucket, but read via a DcpStream. Loosing DcpStream should only close a DcpStream - you can still have a Producer running, maybe the client is going to next create a new stream against a different collection.

So this code is complementary to the code we have in ep-engine - and this code cares when the Producer priv is lost - which is the overall privilege for having a DcpProducer irrespective of the streams.
----------------------------------------------------------------------------------------------------------------------
Author: Trond Norbye
Date: 2022-06-30 13:28:37.000000000
MISMATCHED INLINE COMMENT
Line:723, daemon/connection.cc -> I'm not sure I agree... The other operations we're completing operate on a "single document" (except for privileged operations like delete bucket, flush etc), and we check that you have the appropriate access when we start performing the operation. The reason why we only checked it when we _started_ the operation was that we noticed some problems in ep-engine that the core first told it to start a task, then it notified us that it was done (and possibly held the object in some state/queue waiting for us to call down again). Then the next time the core wanted to operate on the object it now failed with access and ep-engine was only told of a disconnect (I don't remember the exact details, but jim might as I vaguely recall he being the one to added the check to bypass the next check). (stats multi-response is dictated by the on-the-wire spec, and could/should have been changed to return it in a single response. We could always have rechecked the privilege every time we put each value and stopped immediately... but the execution time window is considered so small that it doesn't really add much value.. was it before or after memcached got the notice that privilege was changed etc).

Sending data over a DCP stream is however something different.. it is a long stream of mutations which may take quite some time and we need to disconnect them at some point. From my understanding there is code in place in EPE to stop streaming certain collections if the access to them change. In the case in the patch the user no longer have _ANY_ DCP access to the bucket; and should be deleted as soon as possible before sending more documents to the user (like we do for normal requests; we check the access before sending the document). 

The number of documents in a snapshot is also hard to predict. Are you talking about a stream which is already pretty caught up, or are you talking about a new connector I'm just setting up for the first time? I just ran DCPdrain on my bucket with 5 000 000 items, and they got sent to me with one snapshot per vbucket. It seems wrong to send 4 500 000 items to a user who no longer have access (if you suddenly discover that the account has been compromised and want to stop the malicious user from downloading the entire bucket), at least when we easily can stop it.
----------------------------------------------------------------------------------------------------------------------
