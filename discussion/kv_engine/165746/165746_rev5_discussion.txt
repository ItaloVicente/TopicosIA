======================================================================================================================
DESCRIPTION:

MB-49525: Reduce defragmenter scoring for low hash-table usage

Firstly define a new configuration value (todo...) that means auto
reconfiguration is skipped unless we detect a reasonable number
of objects (StoredValues) we can reallocate. When under that threshold
the defragmenter runs in default configuration.

When above that threshold compute what a ratio of the size of memory
that the defragmenter can affect, that is the memory held by items in
the HashTable. The HashTable holds StoredValues and Blobs (we ignore
the fact that a Blob can be owned by an Item only), so we sum the two
counters from EPStats and calculate a ratio of the bucket's allocated
memory.

The defragmenter will now use the existing score multiplied by this
new ratio to obtain the score for use in defragmenter auto
configuration.

The result is that in cases where fragmentation may appear high, but
the HashTable usage is a small fraction of the allocated memory the
defragmenter stays steady or has a less aggressive ramp up. As
HashTable memory begins to dominate the allocated memory we will
see more aggressive speed up.

Change-Id: I2c52567f6559ccb74ba8a7fbc5cf1428605b0ef1

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Jim Walker
Date: 2021-11-16 13:04:46.000000000
Message: 
Uploaded patch set 5.
----------------------------------------------------------------------------------------------------------------------
Author: Jim Walker
Date: 2021-11-16 13:08:48.000000000
Message: 
Patch Set 5:

(1 comment)
Line:276, engines/ep/src/defragmenter.cc -> I might need to adjust the thresholds (lower/upper) as s2 is never going to be 1.0, the resulting score is always going to be less with this commit

Will likely grab some data from supportal and our defragger perf tests and see what comes out - if this approach seems reasonable i'll do that next step and repost

----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2021-11-16 13:24:30.000000000
Message: 
Patch Set 5: Verified-1

Build Failed 

http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/15915/ : FAILURE

Compile error at [2021-11-16T13:06:11.155Z] ../kv_engine/auditd/tests/testauditd.cc:11:10:
fatal error: folly/portability/GTest.h: No such file or directory
 ( http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/15915/ )

http://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/35491/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/41793/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_tidy-master/14012/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_format_9/12816/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/3722/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/3647/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/15636/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/14805/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/24001/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/16639/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2021-11-17 16:00:45.000000000
Message: 
Patch Set 5: Verified+1

Build Successful 

http://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/35491/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/41793/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_tidy-master/14012/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_format_9/12816/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/3722/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/3647/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/15636/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/14805/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/24001/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/16639/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/15947/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2021-11-23 10:53:23.000000000
Message: 
Patch Set 5:

(1 comment)

My main comment here is we now have a two-dimensional scaling; which could be quite difficult to reason about / calibrate.

Is there any way we could formulate this as a single-dimension of how fragmented we are? Maybe somehow reduce RSS based on how much non-StoredValue / Blob memory is used? I don't know if have the right counters for this...
Line:9, /COMMIT_MSG -> Do we still want a config param for this?

----------------------------------------------------------------------------------------------------------------------
Author: Jim Walker
Date: 2021-11-26 14:41:10.000000000
Message: 
Patch Set 5:

> Patch Set 5:
> 
> (1 comment)
> 
> My main comment here is we now have a two-dimensional scaling; which could be quite difficult to reason about / calibrate.
> 
> Is there any way we could formulate this as a single-dimension of how fragmented we are? Maybe somehow reduce RSS based on how much non-StoredValue / Blob memory is used? I don't know if have the right counters for this...

I've yet to come up with a better method (and looking at MB-49702 where magma is using ~1GB), something is always skewed, mainly because arena.rss is polluted with so many other things.

I'm thinking either

a) adjust the min_sleep parameter only, 1s? Then in all the examples we've seen, we just cap at that value.

b) Stick with something like this and also do a) plus maybe some other tweaks to the config params at play here using data from various recent MBs and some real user data
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2021-11-29 10:00:39.000000000
Message: 
Patch Set 5:

> Patch Set 5:
> 
> > Patch Set 5:
> > 
> > (1 comment)
> > 
> > My main comment here is we now have a two-dimensional scaling; which could be quite difficult to reason about / calibrate.
> > 
> > Is there any way we could formulate this as a single-dimension of how fragmented we are? Maybe somehow reduce RSS based on how much non-StoredValue / Blob memory is used? I don't know if have the right counters for this...
> 
> I've yet to come up with a better method (and looking at MB-49702 where magma is using ~1GB), something is always skewed, mainly because arena.rss is polluted with so many other things.
> 
> I'm thinking either
> 
> a) adjust the min_sleep parameter only, 1s? Then in all the examples we've seen, we just cap at that value.
> 
> b) Stick with something like this and also do a) plus maybe some other tweaks to the config params at play here using data from various recent MBs and some real user data

Yeah, with skew from other places it's going to be challenging to get this more "accurate" without say more statistics (e.g. aforementioned extra jemalloc arenas).

What about going with (a) initially; possibly following up with (b) depending on how things look? That has the advantage of being very simple (just tweak the minimum), and but still gives us a degree of increased aggressiveness compared to pre-7.0.2 Defregmanter (IIRC the default sleep time there was 10s).
----------------------------------------------------------------------------------------------------------------------
