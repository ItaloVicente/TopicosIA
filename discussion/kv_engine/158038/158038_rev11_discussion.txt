======================================================================================================================
DESCRIPTION:

MB-47386: Make CM::extractClosedUnrefCheckpoints O(1)

That is one of the major O(N = checkpoint-list-size) operations that we
do under CM::lock. Which can become very expensive if we allow a high
number of checkpoints in the list, thus impacting frontend operations.

The related benchmark results show that before this change the runtimes
of the function progressed linearly with the workload, while now they
stay constant at any workload:

$ ./ep_engine_benchmarks --benchmark_filter="ExtractClosedUnrefCheckpoints" --benchmark_repetitions=10
Run on (24 X 2400 MHz CPU s)
CPU Caches:
  L1 Data 32 KiB (x12)
  L1 Instruction 32 KiB (x12)
  L2 Unified 256 KiB (x12)
  L3 Unified 15360 KiB (x2)

[before]
-------------------------------------------------------------------------------------------------------------------
Benchmark                                                                         Time             CPU   Iterations
-------------------------------------------------------------------------------------------------------------------
CheckpointBench/ExtractClosedUnrefCheckpoints/100/iterations:1_median          8408 ns         6721 ns           10
CheckpointBench/ExtractClosedUnrefCheckpoints/1000/iterations:1_median        40237 ns        37663 ns           10
CheckpointBench/ExtractClosedUnrefCheckpoints/10000/iterations:1_median      734348 ns       728692 ns           10
CheckpointBench/ExtractClosedUnrefCheckpoints/100000/iterations:1_median   11918034 ns     11915072 ns           10

[after]
-------------------------------------------------------------------------------------------------------------------
Benchmark                                                                         Time             CPU   Iterations
-------------------------------------------------------------------------------------------------------------------
CheckpointBench/ExtractClosedUnrefCheckpoints/100/iterations:1_median          7179 ns         5385 ns           10
CheckpointBench/ExtractClosedUnrefCheckpoints/1000/iterations:1_median         8166 ns         5852 ns           10
CheckpointBench/ExtractClosedUnrefCheckpoints/10000/iterations:1_median       13649 ns         8157 ns           10
CheckpointBench/ExtractClosedUnrefCheckpoints/100000/iterations:1_median      14685 ns         8573 ns           10

Change-Id: I5ba3cc890c0eb4023b425b3312f05c084e05fcd0

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Paolo Cocchi
Date: 2021-08-13 05:51:25.000000000
Message: 
Uploaded patch set 11.
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2021-08-13 06:07:21.000000000
Message: 
Patch Set 11: Verified-1

Build Failed 

http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/13454/ : FAILURE

ThreadSanitizer issue: data race tlm/deps/boost.exploded/include/boost/intrusive/detail/size_holder.hpp:52 in boost::intrusive::detail::size_holder<true, unsigned long, void>::decrease(unsigned long)  ( http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/13454/ )

http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/13089/ : FAILURE

Failure of GoogleTest "EphemeralOrPersistent/STExpiryPagerTest.MB_25671/persistent_magma_full_eviction":

<pre>
[ RUN      ] EphemeralOrPersistent/STExpiryPagerTest.MB_25671/persistent_magma_full_eviction
[2021-08-13T06:00:11.250Z] ../kv_engine/engines/ep/tests/module_tests/item_pager_test.cc:1564: Failure
[2021-08-13T06:00:11.250Z] Expected equality of these values:
[2021-08-13T06:00:11.250Z]   cb::engine_errc::would_block
[2021-08-13T06:00:11.250Z]     Which is: would block
[2021-08-13T06:00:11.250Z]   getKeyFn(key_2)
[2021-08-13T06:00:11.250Z]     Which is: no memory
[2021-08-13T06:00:11.250Z] ../kv_engine/engines/ep/tests/module_tests/item_pager_test.cc:1567: Failure
[2021-08-13T06:00:11.250Z] Expected equality of these values:
[2021-08-13T06:00:11.250Z]   cb::engine_errc::no_such_key
[2021-08-13T06:00:11.250Z]     Which is: no such key
[2021-08-13T06:00:11.250Z]   getKeyFn(key_2)
[2021-08-13T06:00:11.250Z]     Which is: would block
[2021-08-13T06:00:11.250Z] Key with TTL:20 should be removed.
[2021-08-13T06:00:11.250Z] [  FAILED  ] EphemeralOrPersistent/STExpiryPagerTest.MB_25671/persistent_magma_full_eviction, where GetParam() = ("persistent_magma", "full_eviction") (44 ms)
EphemeralOrPersistent/STExpiryPagerTest.MB_25671/persistent_magma_full_eviction
</pre>
 ( http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/13089/ )

http://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/934/ : FAILURE

No problems were identified. If you know why this problem occurred, please add a suitable Cause for it. ( http://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/934/ )

http://cv.jenkins.couchbase.com/job/kv_engine-clang_format_9/9991/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/38574/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_tidy-master/11295/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/32890/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/926/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/12894/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/21004/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/12011/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2021-08-13 06:50:46.000000000
Message: 
Patch Set 11:

Build Failed 

http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/13455/ : FAILURE

Failure of an engine_testapp test:

<pre>
Running [0092/0093]: test oso backfill...(68 ms) SKIPPED_UNDER_MAGMA
[2021-08-13T06:47:52.210Z] # Passed 93 of 93 tests
[2021-08-13T06:47:52.210Z] ThreadSanitizer: reported 1 warnings
[2021-08-13T06:47:52.210Z] 
[2021-08-13T06:47:54.741Z] 394/397 Test #390: memcached_testapp.ep.TransportProtocols/ArithmeticTest ......................................................   Passed   11.22 sec
[2021-08-13T06:48:03.344Z] 395/397 Test #392: memcached_testapp.ep.TransportProtocols/AuditTest ...........................................................   Passed   17.84 sec
[2021-08-13T06:48:04.275Z] 396/397 Test #376: memcached_testapp.ep.TransportProtocols/GetSetTest ..........................................................   Passed   27.71 sec
[2021-08-13T06:49:00.469Z] 397/397 Test #395: cluster_test ................................................................................................   Passed   66.23 sec
[2021-08-13T06:49:00.469Z] 
[2021-08-13T06:49:00.469Z] 99% tests passed, 2 tests failed out of 397
[2021-08-13T06:49:00.469Z] 
[2021-08-13T06:49:00.469Z] Total Test time (real) = 659.87 sec
[2021-08-13T06:49:00.469Z] 
[2021-08-13T06:49:00.469Z] The following tests FAIL
</pre>
 ( http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/13455/ )

ThreadSanitizer issue: data race tlm/deps/boost.exploded/include/boost/intrusive/detail/size_holder.hpp:37 in boost::intrusive::detail::size_holder<true, unsigned long, void>::get_size() const  ( http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/13455/ )

http://cv.jenkins.couchbase.com/job/kv_engine-clang_format_9/9991/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/38574/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_tidy-master/11295/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/32890/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/926/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/12894/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/13090/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/935/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/21004/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/12011/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2021-08-13 08:46:31.000000000
Message: 
Patch Set 11: Verified+1

So the only failure in CV is at http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/13455/console where TSAN has spotted a legit data-race in CM.
The data-race is not introduced in this patch, so I'll set CV+1.
Why does TSAN sees that data-race only now? Not sure, but probably that's related to changing the CheckpointList's underlying type.
Fix for the data-race tracked in MB-47932.
----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2021-08-13 08:46:35.000000000
Message: 
Removed Verified-1 by Build Bot <build@couchbase.com>

----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2021-08-13 10:04:50.000000000
Message: 
Patch Set 11: Code-Review-1

(1 comment)
Line:541, engines/ep/benchmarks/vbucket_bench.cc -> I think 100,000 checkpoints is a pretty large number - even if they were say small and had just 10 items in them, that's still 1M items queued in that vBucket!

Suggest we move the range down a bit - test 1 and 10 checkpoints (I expect that's closer to the common case) and maybe stop at 10k?

----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2021-08-13 10:26:00.000000000
Message: 
Patch Set 11:

(1 comment)
Line:541, engines/ep/benchmarks/vbucket_bench.cc -> Sure can show at any size, but:

On the low end, 1 and 10 don't show any big difference with 100 even before the optimization. That's why I've picked 100 as a starting point here.

On the high end, in the past we reached sizes in the order of 50k-60k, and that was when we tried to "close checkpoint at every snap-end mutation at PassiveStream" ðŸ˜„ .. That's where a huge frontend degradation came up, that's why the 100k here. Who knows, maybe we are re-doing that at some point when all O(N) code in CM is gone :shrugh:

----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2021-08-13 10:42:10.000000000
Message: 
Patch Set 11:

(1 comment)
Line:541, engines/ep/benchmarks/vbucket_bench.cc -> > On the low end, 1 and 10 don't show any big difference with 100 even before the optimization. That's why I've picked 100 as a starting point here.

Sure, but that's important information for an observer - at the moment _I_ don't know what the behaviour of 1 / 10 is, for all I know 1 checkpoint could be 2x slower with the O(1) code (say constant factors are larger and they dominate) which would potentially be an issue.

> On the high end, in the past we reached sizes in the order of 50k-60k, and that was when we tried to "close checkpoint at every snap-end mutation at PassiveStream" ðŸ˜„ .. That's where a huge frontend degradation came up, that's why the 100k here. 

Sure, but that's ultimately a result of allowing arbitrarily large flush batches in the first place (which we know we need to look at constraining in size and potentially at checkpoint boundaries.

My point is more that across a whole bucket it seems much too high to allow a (memory) checkpoint on active to grow to 100K items, as that implies there's 100M mutations in flight (at a minimum) across the entire cluster.

I'm less concerned about you keeping an 100K variant for the sake of seeing how things scale, but we really shouldn't be growing checkpoints anywhere near that size IMHO.

Recall the only reason checkpoints arn't say 1 item (slight exaggeration, but still...) is to allow de-duplication in CheckpointManager. I don't think there's value in allowing de-duplication across say 100k items, there's definitely value over say 10, the question is where is the cutoff point?...

----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2021-08-13 11:25:26.000000000
Message: 
Patch Set 11:

(1 comment)
Line:541, engines/ep/benchmarks/vbucket_bench.cc -> Done

----------------------------------------------------------------------------------------------------------------------
