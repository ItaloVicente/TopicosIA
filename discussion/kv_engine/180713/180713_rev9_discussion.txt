======================================================================================================================
DESCRIPTION:

MB-46740: Limit the size of ActiveStream::readyQ

Before this patch the ActiveStream Task pulls all the checkpoint
outstanding items for cursor and pushes them into the Stream::readyQ.

That behaviour is the reason why the allocation in readyQ can take a
significant chunk of the BucketQuota. High allocations in the readyQ
have been observed multiple times, eg MB-53590 as one of the most
recent.

This patch changes the ActiveStream Task behaviour so that it tries
to limit to preferably checkpoint_max_size_bytes the size of the
snapshot generated by cursor-move and pushed into the readyQ.

The actual expected max size is (2 * checkpoint_max_size_bytes)
though.
That is because (for DCP in particular) CM needs to generate
consistent snapshots, so a DCP cursor might pull more than
checkpoint_max_size_bytes. Eg in a case were
  - Cursor moves to the end of its current checkpoint -> total
    snapshot size just below checkpoint_max_size_bytes
  - Cursor jumps into the next checkpoint (if any) and pulls
    everything from there too
, then Task would push to the readyQ up to 2 full checkpoints.

Given that the ActiveStream frontend pulls from checkpoint only when
the readyQ is empty (ie, all ready items streamed to the DCP client),
then (2 * checkpoint_max_size_bytes) is the new theretical size limit
for each stream readyQ.

Just for making an example, in a scenario like:
  - BucketQuota = 1GB
  - checkpoint_memory_ratio = 30% of BucketQuota = 300MB
  - max_checkpoints = 10
  - num_vbuckets = 64
  - 2 nodes, 1 replica

, then before this change the allocation in the stream's readyQ(s) on a
single DCP Producer can grow up tp 300MB, as nothing's preventing the
ActiveStream Task from pulling a full CM and pushing all items into
readyQ(s).

While with this change:
  - checkpoint_max_size_bytes = CMQuota / max_checkpoints /
      num_vbuckets ~ 480KB
  - single readyQ = 2 * checkpoint_max_size_bytes = 960KB
  - 32 readyQ(s) per node -> ~ 30MB in total

Change verified on tests in MB-53590 (bulk-load via restore). The
baseline runs suffer from uncapped allocations in the Stream::readyQ
that cause memcacahed continously jumping in/out TempOOM phases.
Test repetition on this change (toy run) shows the memcached mem-usage
never crossing the HWM. Result is:
  - No TempOOMs
  - Ingestion throughput gets a 3x boost
  - Overall improved memory control allows to end the test at
   ActiveRR=12% (rather than 0% at baseline)
See MB-53590 for details.

- Notes-

Why using checkpoint_max_size_bytes as theoretical limit (and not some
other quantity) ?
Checkpoint's max size is a sensible quantity as the checkpoint is the
replication queue.
Since MB-50984, that quantity is a hard limit on the single checkpoint.
Also, that scales nicely on Bucket/CM quotas.

Why not limiting the readyQ to exactly 1 checkpoint?
That is suboptimal in cases where checkpoints are closed before
reaching checkpoint_max_size_bytes (eg, SyncWrite and SystemEvent). In
those cases we might end up with checkpoints that contain just a few
items, which means that processing checkpoint_max_size_bytes would
require too many DCP loops.

Change-Id: Id4ecee911550834d209434bbf76480f73fae32fd

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Paolo Cocchi
Date: 2022-10-04 12:27:03.000000000
Message: 
Uploaded patch set 9.
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2022-10-04 12:51:45.000000000
Message: 
Patch Set 9: Verified-1

Build Failed 

https://cv.jenkins.couchbase.com/job/kv_engine-windows-master/49939/ : FAILURE

Failure of GoogleTest "CollectionsEraserSyncWriteTests/CollectionsEraserSyncWriteTest.EraserFindsPrepares/persistent_couchstore_full_eviction":

<pre>
[ RUN      ] CollectionsEraserSyncWriteTests/CollectionsEraserSyncWriteTest.EraserFindsPrepares/persistent_couchstore_full_eviction
unknown file: error: C++ exception with description "KVStoreFactory ctor: Specified dbname "ep_engine_ep_unit_tests.db/test.244003" is not a directory" thrown in SetUp().
unknown file: error: SEH exception with code 0xc0000005 thrown in TearDown().
[  FAILED  ] CollectionsEraserSyncWriteTests/CollectionsEraserSyncWriteTest.EraserFindsPrepares/persistent_couchstore_full_eviction, where GetParam() = "bucket_type=persistent:backend=couchstore:item_eviction_policy=full_eviction" (179 ms)
CollectionsEraserSyncWriteTests/CollectionsEraserSyncWriteTest.EraserFindsPrepares/persistent_couchstore_full_eviction
</pre>
 ( https://cv.jenkins.couchbase.com/job/kv_engine-windows-master/49939/ )

https://cv.jenkins.couchbase.com/job/kv_engine-clang_format_9/20090/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine-clang_tidy-master/20858/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/41952/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/10574/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/22847/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/23243/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/22252/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/24086/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/31261/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/10674/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
