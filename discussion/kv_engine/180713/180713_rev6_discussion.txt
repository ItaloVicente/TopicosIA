======================================================================================================================
DESCRIPTION:

MB-46740: Limit the size of ActiveStream::readyQ

Before this patch the ActiveStream Task pulls all the checkpoint
outstanding items for cursor and pushes them into the Stream::readyQ.

That behaviour is the reason why the allocation in readyQ can take a
relevant chunk of the BucketQuota. High allocations in the readyQ have
been observed multiple times, eg MB-53590 as one of the most recent.

This patch changes the ActiveStream Task behaviour to limiting to
checkpoint_max_size_bytes the size of the snapshot generated by
cursor-move and pushed into the readyQ.

Given that the ActiveStream frontend pulls from checkpoint only when
the readyQ is empty (ie, all ready items streamed to the DCP client),
then checkpoint_max_size_bytes is the new theretical size limit for
each stream readyQ.

As usual for checkpoint consumers, the actual size of what is returned
from CM can vary from the theretical limit. That is because (for DCP in
particular) CM needs to generate consistent snapshots that can be
greater than checkpoint_max_size_bytes.

Eg in a case were
  - Cursor moves to the end of its current checkpoint -> total
    snapshot size just below checkpoint_max_size_bytes
  - Cursor jumps into the next checkpoint (if any) and pulls
    everything from there too
, then Task would push to the readyQ up to 2 full checkpoints.

Just for making an example, in a scenario like:
  - BucketQuota = 1GB
  - checkpoint_memory_ratio = 30% of BucketQuota = 300MB
  - max_checkpoints = 10
  - num_vbuckets = 64
  - 2 nodes, 1 replica

, then before this change the allocation in the stream's readyQ(s) on a
single DCP Producer can grow up tp 300MB, as nothing's preventing the
ActiveStream Task from pulling a full CM and pushing all items into
readyQ(s).

While with this change:
  - checkpoint_max_size_bytes = CMQuota / max_checkpoints /
      num_vbuckets ~ 480KB
  - single readyQ = 2 * checkpoint_max_size_bytes = 960KB
  - 32 readyQ(s) per node -> ~ 30MB in total

Change verified on tests in MB-53590 (bulk-load via restore). The
baseline runs suffer from uncapped allocations in the Stream::readyQ
that cause memcacahed continously jumping in/out TempOOM phases.
Test repetition on this change (toy run) shows the memcached mem-usage
never crossing the HWM. Result is:
  - No TempOOMs
  - Ingestion throughput gets a 3x boost
  - Overall improved memory control allows to end the test at
   ActiveRR=12% (rather than 0% at baseline)
See MB-53590 for details.

- Notes-

Why using checkpoint_max_size_bytes as theretical limit (and not some
other quantity) ?
Checkpoint's max size is a sensible quantity as the checkpoint is the
replication queue.
Also, that quantity scales nicely on Bucket/CM quotas.

Why not limiting the readyQ to exactly 1 checkpoint?
That is suboptimal in cases where checkpoints are closed before
reaching checkpoint_max_size_bytes (eg, SyncWrite and SystemEvent). In
those cases we might end up with checkpoints that contain just a few
items, which means that draining the replication queue would require
too many DCP loops.

Change-Id: Id4ecee911550834d209434bbf76480f73fae32fd

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Paolo Cocchi
Date: 2022-10-04 07:29:48.000000000
Message: 
Uploaded patch set 6: Commit message was updated.
----------------------------------------------------------------------------------------------------------------------
