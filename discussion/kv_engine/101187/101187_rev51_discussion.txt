======================================================================================================================
DESCRIPTION:

MB-31869: Provide ability for consumer to not buffer DCP messages

First, let's sum up how FlowControl currently works. That is related to
Replication Throttling and DCP buffering at Consumer.

1) Producer and Consumer negotiates a max DCP buffer size when the DCP
connection is initialized. This buffer size becomes the size of the
BufferLog at Producer, see below.

2) The Producer starts sending messages to the Consumer. The Producer
adds the number of bytes sent to its BufferLog. The Consumer receives
messages and acks back the bytes received to the Producer via BufferAck.

3) The Producer receives BufferAcks and removes bytes from its
BufferLog.

4) The Producer pause if the BufferLog is full. That happens when (for
any reason) the Consumer delays in ingesting the inbound DCP traffic.

As (4) suggests, OOM at Consumer is only one reason why the Consumer may
delay in processing incoming DCP messages and acking bytes back to the
Producer.

And now on Replication Throttling.
Replication Throttling guards the Consumer for OOM. We have a
Replication Throttling Threshold (defaulted to 99% of the bucket quota)
which is where the Consumer stops processing the received DCP messages.

The Consumer acks back to the Producer only bytes of messages processed.
So again, if Throttling kicks is then the Consumer stops acking bytes back
to the Producer. This time for an OOM condition.

Now on the DCP buffering at Consumer, which is the core of this patch.
How does that fit in what I have described above?
When the Consumer hits OOM, it stops processing messages by adding them
into each PassiveStream::buffer. Bytes for buffered messages are *not*
acked, which means that at some point the BufferLog at Producer becomes
full and replication pauses.

This patch just provides an alternative to buffering at Consumer. Rather
than buffering messages we just pause the Consumer when we hit OOM.
That means not draining the inbound socket buffer at Consumer and not
acking bytes back to the Producer. As soon as we recover from the OOM
condition, we unpause the Consumer and everyting proceed as usual. Which
leaves the throttling mechanism logically unchanged.

First of all, that simplifies the logic considerably at Consumer in an
area that has already caused issues (eg, MB-31547).
Plus, doing extra buffering on a node that has already hit OOM doesn't
really help.

A configuration parameter is provided to allow easy switching between
using the buffer or not. Once we have gained confidence in not using
the buffer the switch and associated buffering code will be removed.

Change-Id: I1e87caeddd3f520c7eb1ee7ccf77043461df9d0b

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Paolo Cocchi
Date: 2020-09-16 12:06:28.000000000
Message: 
Uploaded patch set 51.
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2020-09-16 14:44:37.000000000
Message: 
Patch Set 51: Verified+1

Build Successful 

http://cv.jenkins.couchbase.com/job/kv_engine-clang_format_9/3087/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_tidy/4560/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/26359/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/30486/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/5815/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/5935/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/6057/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/13732/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/4917/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2020-09-16 15:08:47.000000000
Message: 
Patch Set 51:

CV green at last ! ðŸ˜Ž
----------------------------------------------------------------------------------------------------------------------
Author: Ben Huddleston
Date: 2020-09-18 12:50:10.000000000
Message: 
Patch Set 51: Code-Review+1

(4 comments)

Code looks fine to me, couple comments about the tests
Line:81, engines/ep/src/checkpoint_visitor.cc -> did you consider only doing this if we are going from high memory usage to less high memory usage?

Line:1120, engines/ep/tests/module_tests/dcp_durability_stream_test.cc -> why is this, here and below, necessary?

Line:2116, engines/ep/tests/module_tests/dcp_stream_test.cc -> can you just do "resetEngingAndWarmup("dcp_consumer_throttling_buffer_enabled=true");"

Line:2942, engines/ep/tests/module_tests/dcp_stream_test.cc -> can't quite remember but doesn't MockCookie do this already?

----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2020-09-18 15:15:54.000000000
Message: 
Patch Set 51:

(2 comments)
Line:1120, engines/ep/tests/module_tests/dcp_durability_stream_test.cc -> That is for avoiding a heap-use-after-free at resetEngineAndWarmup() (ConnMap::manageConnections() would access a released cookie).

Note that the need fo connmap::removeConn() is introduced by http://review.couchbase.org/c/kv_engine/+/101187/51/engines/ep/tests/module_tests/dcp_stream_test.cc#1657

Line:2116, engines/ep/tests/module_tests/dcp_stream_test.cc -> That's not equivalent as I have to reset also passive stream and connection

void SingleThreadedPassiveStreamTest::SetUp() {
    STParameterizedBucketTest::SetUp();

    setVBucketStateAndRunPersistTask(vbid, vbucket_state_replica);

    setupConsumerAndPassiveStream();
}

void SingleThreadedPassiveStreamTest::TearDown() {
    ASSERT_NE(ENGINE_DISCONNECT, consumer->closeStream(0 /*opaque*/, vbid));
    static_cast<MockDcpConnMap&>(engine->getDcpConnMap()).removeConn(cookie);
    consumer.reset();

    STParameterizedBucketTest::TearDown();
}

----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2020-09-18 15:17:53.000000000
Message: 
Patch Set 51:

(1 comment)
Line:1120, engines/ep/tests/module_tests/dcp_durability_stream_test.cc -> note that 
  consumer->closeStreams()
  connmap->removeConn
  consumer->reset()

should be definitely put moved in a helper function :| doing

----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2020-09-21 14:03:36.000000000
Message: 
Patch Set 51:

(2 comments)
Line:1120, engines/ep/tests/module_tests/dcp_durability_stream_test.cc -> Done

Line:2942, engines/ep/tests/module_tests/dcp_stream_test.cc -> No for what I see.. This is a MockServerCookieApi thing

----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2020-09-21 14:15:33.000000000
Message: 
Patch Set 51: Code-Review-1

(1 comment)
Line:81, engines/ep/src/checkpoint_visitor.cc -> As discussed, checking the ReplicationThrott::Status is not enough for preventing unnecessary calls to ConnMap but checking if we went high-to-low mem is not enough either.
Imagine the common case where we execute here, mem-usage is below the ReplThreshold but there is no paused connection in ConnMap. In that case we would always scan the ConnStore for paused connection.
Working on a solution.

----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2020-09-22 10:14:36.000000000
Message: 
Patch Set 51: -Code-Review
----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2020-09-22 10:15:24.000000000
Message: 
Patch Set 51:

(1 comment)
Line:81, engines/ep/src/checkpoint_visitor.cc -> New patchset up - approaching the same as for Backfill above

----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2020-09-28 07:25:11.000000000
MISMATCHED INLINE COMMENT
Line:81, engines/ep/src/checkpoint_visitor.cc -> Tried to prevent the unnecessary call to ConnMap by doing something similar to what we currently do for Backfill (see line 71-74 above), but that may cause issues. See comment at http://review.couchbase.org/c/kv_engine/+/101187/53/engines/ep/src/checkpoint_visitor.cc#38 for details.

Just checking the ReplThrott status seems fine for now. The call to ConnMap is a NOP if there is no connection paused by OOM. From a perf PoV we can improve this by checking if there is any connection paused by OOM before scanning the ConnMap::ConnStore::cookieToConnMap. But the problem is that currently getting that information requires scanning the connMap itself. We can solve in different ways:

1) Using a dedicated PausedByOomMap - Getting the size would be O(1) and we would even avoid scanning the entire CookieToConnMap when it's time to wakeup connections. Cons: we need change ConnStore

2) Storing a 'numPausedByOOM' counter - O(1) when checking if we need to call down to ConnMap, but still O(N) when calling down to ConnMap - Pros: small change.

Question: can the number of DCP connections get so big to create any real issue here?

Note also that here we are in Visitor::complete(). We don't hold any lock to any major struct (HT / CM). Locks to the ConnStore::cookieToConnMap are hold only at Conn/Stream setup/tear-down + ConnManger (when notifying paused connections). By code-inspection I don't see any evident frontend/DCP throughput degradation caused by this change if the size of ConnStore::cookieToConnMap stays reasonably small.
----------------------------------------------------------------------------------------------------------------------
Author: Ben Huddleston
Date: 2020-10-01 12:36:26.000000000
MISMATCHED INLINE COMMENT
Line:81, engines/ep/src/checkpoint_visitor.cc -> I think we could reasonably have hundreds of DCP connections, but probably not thousands. One usage of cookieToConnMap I think you missed is stats (see EventuallyPersistentEngine::doConnAggStats and EventuallyPersistentEngine::doDcpStats). Probably fine to leave as it currently is and if we do have some regression then can address that later.
----------------------------------------------------------------------------------------------------------------------
