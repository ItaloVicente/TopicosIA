======================================================================================================================
DESCRIPTION:

MB-51875: Add support for collecting metering data [2/n]

Add the skeleton for collecting metering information. Note that
all commands implemented in the engine itself would need to
update the cookie with the amount of data read / written

It is "easy" to track the write path as a successful document write
contains the WCU. We can't really use the bucket_get() methods for
counting the RCU's as we do multiple of them and might not return
the data to the user (also to implement retry logic on the server
for dealing with cas conflicts)

The intention with this patch is to get the infrastructure in
place, so that we can fan out the work to:

1) Get the RCU/WCU pushed to prometheus
2) Create a spec on how to calculate the RCU/WCU for the
   various commands
3) Account for RCU and WCU for the various commands according
   to 2.

Change-Id: I20d4b7779db95d73236c667255e232b09771f786

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Trond Norbye
Date: 2022-04-20 14:16:17.000000000
Message: 
Uploaded patch set 15.
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-04-20 14:47:32.000000000
Message: 
Patch Set 15: Code-Review-1

(4 comments)
Line:14, /COMMIT_MSG -> Note that inside ep-engine there's already the concept of get()-like operations passing in a get_options_t which amongst other things specified a TRACK_STATISTICS flag; the idea being we only track stats for operations which are "directly" performed by the user.

We could expand that to handle metering, so the final count of how much data is read / written etc is done by ep-engine.

However... isn't RCU more about externally-visible requests? i.e. if I do a GET(doc1), I would expect that the RCU cost of that is simply the number of 1KB chunks the request returns.

Similary, if I do a SUBDOC_LOOKUP(doc2, path=foo.bar) against a 20MB document, but path "foo.bar" is only 1KB, I would only expect to be charged 1 RCU?

i.e I don't think we should be accounting what we have to read to do our job, but what we send to the user. Otherwise (in the subdoc case) there's basically no benefit to the user in using subdoc; they get charged the whole doc price.

Line:95, daemon/buckets.cc -> Nit: You can do this without the conditional via:

 const auto rcd = read + (read_compute_unit_size - 1) / read_compute_unit_size;

Line:186, daemon/buckets.h -> Please document these.

Line:263, daemon/protocol/mcbp/arithmetic_context.cc -> Given my comments on the commit message, does it make sense to just handle DocumentReadBytes as part of cookie.sendResponse? i.e. we meter whatever is sent back to the user? (possibly only for successful responses?)

----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2022-04-20 15:00:26.000000000
Message: 
Patch Set 15: Verified+1

Build Successful 

http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/45421/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/38159/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_tidy-master/16803/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_format_9/15737/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/18586/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/18922/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/6532/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/26991/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/17683/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/6460/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/19624/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Trond Norbye
Date: 2022-04-20 15:05:52.000000000
Message: 
Patch Set 15:

(4 comments)
Line:14, /COMMIT_MSG -> There is a separate task (MB-51876) to reach out and get the requirements for how we should do the tracking as there currently isn't any requirements written down (all it say is RCU and WCU). 

The current "WIP" do exactly what you mention above; RCU is accounted for what being returned to the user over the wire, but WCU is the entire payload we write to disk (as we currently can't do partial writes; well with subdoc you may ship a partial write to the server, but we'll still end up doing a full write).

The intention of this patch is more to get the "infrastructure" up'n'running so that someone may fix MB-51876, and someone else may fix MB-51874 to scrape these statistics so they may be consumed by the dataplane for metering).

Line:95, daemon/buckets.cc -> something one may change later if one prefer.. focusing on refactoring the state machine to allow throttling to make other progress on elixir

Line:186, daemon/buckets.h -> Ok.. personally I felt that they're pretty self documented by the actual long variable name...

Line:263, daemon/protocol/mcbp/arithmetic_context.cc -> I'm not fully sure... then we would have to add per-opcode-logic in there to know if we should include it or not.. From my understanding we're only supposed to account for this for "normal data usage", so that running stats (for instance) wouldn't bump RCU at all... 

Anyway.. As I mentioned earlier; we need to get the requirements in place on what should be included in RCU/WCU; but it shouldn't block being able to get the data to prometheus (and folks on the dataplane to collect that).

----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2022-04-20 15:07:10.000000000
Message: 
Patch Set 15: Verified-1

Build Failed 

http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/26987/ : ABORTED

Build which was aborted due to a newer patch set being uploaded for the given review. ( http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/26987/ )

http://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/6458/ : ABORTED

Build which was aborted due to a newer patch set being uploaded for the given review. ( http://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/6458/ )

http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/19621/ : ABORTED

Build which was aborted due to a newer patch set being uploaded for the given review. ( http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/19621/ )

http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/18583/ : ABORTED

Build which was aborted due to a newer patch set being uploaded for the given review. ( http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/18583/ )

http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/18919/ : ABORTED

Build which was aborted due to a newer patch set being uploaded for the given review. ( http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/18919/ )

http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/17678/ : ABORTED

Build which was aborted due to a newer patch set being uploaded for the given review. ( http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/17678/ )

http://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/6520/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-04-20 15:12:51.000000000
MISMATCHED INLINE COMMENT
Line:14, /COMMIT_MSG -> Ack.
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-04-20 15:12:51.000000000
MISMATCHED INLINE COMMENT
Line:95, daemon/buckets.cc -> It's just that modulus can be surprisingly costly on some architectures; if we are doing this on every operation it might start to show up...
----------------------------------------------------------------------------------------------------------------------
Author: Trond Norbye
Date: 2022-04-20 15:43:29.000000000
MISMATCHED INLINE COMMENT
Line:95, daemon/buckets.cc -> Seems like a nice job for the optimizer:

    uint64_t calculate_cu(uint64_t bytes, uint64_t size) {
      return bytes / size + (bytes % size ? 1 : 0);
    }

    00000000000011e0 <calculate_cu>:
    11e0:	f3 0f 1e fa          	endbr64 
    11e4:	48 89 f8             	mov    %rdi,%rax
    11e7:	31 d2                	xor    %edx,%edx
    11e9:	48 f7 f6             	div    %rsi
    11ec:	48 83 fa 01          	cmp    $0x1,%rdx
    11f0:	48 83 d8 ff          	sbb    $0xffffffffffffffff,%rax
    11f4:	c3                   	ret
----------------------------------------------------------------------------------------------------------------------
Author: Trond Norbye
Date: 2022-04-21 06:57:51.000000000
MISMATCHED INLINE COMMENT
Line:95, daemon/buckets.cc -> Done
----------------------------------------------------------------------------------------------------------------------
