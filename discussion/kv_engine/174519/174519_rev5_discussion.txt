======================================================================================================================
DESCRIPTION:

MB-35297: Add an optional random sampling feature to RangeScan

The range scan functionality can be adapted so that a client
could request that the scan returns a random number of keys
or documents, providing a random set of documents from the
entire collection (instead of the resident only GetRandomKey)

An optional parameter is added to the create path allowing
for a PRNG seed and sample size to be specified. The random
sample then behaves as follows.

1) Check collection item count, if the collection is greater
than the requested samples continue.

2) Divide the collection item count by the number of samples.
These are termed chunks in the commit, then generate a random
index within a chunk.

3) Run the scan, counting how far along the chunk the scan is
and skipping the keys that are not at the random index.

4) Include the key at the random index in the scan output and
regenerate a new index once the end of the chunk has been
reached.

E.g. with 9 keys and a sample size of 3, 3 chunks are processed
and 1 key from each chunk is selected.

Change-Id: I3ed68ed94e2f222d0c7c9deb9294490f5a9dc37c

---
k0
k1 <- include
k2
---
k3
k4 <- include
k5
---
k6
k7
k8 <- include
---

Change-Id: I3ca3af43e5e04d621a4f1df164fefcaebd106149

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Jim Walker
Date: 2022-05-10 09:23:10.000000000
Message: 
Uploaded patch set 5.
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2022-05-10 09:47:01.000000000
Message: 
Patch Set 5: Verified-1

Build Failed 

http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/27551/ : ABORTED

No problems were identified. If you know why this problem occurred, please add a suitable Cause for it. ( http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/27551/ )

http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/20178/ : ABORTED

No problems were identified. If you know why this problem occurred, please add a suitable Cause for it. ( http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/20178/ )

http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/46030/ : FAILURE

Failure of an engine_testapp test:

<pre>
Running [145/160]: test_MB-19687_fixed...(16 ms) SKIPPED_UNDER_MAGMA


99% tests passed, 1 tests failed out of 428

Total Test time (real) = 689.04 sec

The following tests FAIL
</pre>
 ( http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/46030/ )

Timeout of a CTest test 428/428 Test #281: ep_testsuite.full_eviction.magma ........................................................................} ( http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/46030/ )

http://cv.jenkins.couchbase.com/job/kv_engine-clang_format_9/16394/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_tidy-master/17391/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/38658/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/7095/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/18344/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/7003/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/19151/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/19494/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2022-05-10 13:27:29.000000000
Message: 
Patch Set 5:

Build Failed 

http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/46038/ : FAILURE

Failure of an engine_testapp test:

<pre>
Running [58/160]: ep workload stats...Exceeded maximum wait time of 60000000us waiting for stat "ep_persist_vbstate_total" to be greater or equal than 1 (last value:0) - aborting.
</pre>
 ( http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/46038/ )

Timeout of a CTest test 428/428 Test #295: ep_testsuite_dcp.ephemeral.comp_active ..................................................................} ( http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/46038/ )

http://cv.jenkins.couchbase.com/job/kv_engine-clang_format_9/16406/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_tidy-master/17399/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/38666/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/7103/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/18353/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/7011/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/19159/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/27561/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/19502/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/20186/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2022-05-10 14:38:19.000000000
Message: 
Patch Set 5: Verified+1

Build Successful 

http://cv.jenkins.couchbase.com/job/kv_engine-clang_format_9/16406/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_tidy-master/17399/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/38666/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/7103/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/18353/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/7011/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/19159/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/27561/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/19502/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/20186/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/46042/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-05-11 08:58:37.000000000
Message: 
Patch Set 5: Code-Review-1

(1 comment)
Line:28, /COMMIT_MSG -> I'm not 100% sure, but I suspect this isn't an unbiased random sampling, as we are essentially "forcing" there to only be one sample included in each chunk of the keyspace.

How much this matters I don't know (my statistical maths is pretty rusty); but if one considers a keyspace which is not very uniform - e.g. only one key starting with 'a' but 99 starting with 'b', then I think if you do the maths it's much harder to sample the key 'a' out say 10 samples, as it's only the first chunk it's possible to find the key in.

I think this is related to the same bias issues one gets with shuffling - e.g. https://en.wikipedia.org/wiki/Fisherâ€“Yates_shuffle

I _think_ it would be more unbiased to simply calculate N random numbers in the range (0, collection_size), where N is the sample size; then drive range scans which skip the appropriate number of keys based on the distance between each random sample.

----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-05-11 09:01:14.000000000
Message: 
Patch Set 5:

(1 comment)
Line:28, /COMMIT_MSG -> Here's a motivating example - in your current algo, it would be impossible to sample both k1 and k2 as they both land in the same chunk.

However, from a unbiased random sample pov, it should be equally possible to sample any two keys - e.g. sampling k1 and k2 should be equally as likely as sampling k1 and k4 (which is possible with the current algo).

----------------------------------------------------------------------------------------------------------------------
Author: Jim Walker
Date: 2022-05-11 11:19:41.000000000
Message: 
Patch Set 5:

(1 comment)
Line:28, /COMMIT_MSG -> Yep, i can see your point :) I'll check in with marco about the expected sample size, to generate the indexes ahead, I'd like to cap sample-size. I certainly can't see any smarts that would allow the generation on the fly of the indexes 1 by 1 (in a sequential fashion, as we can't go from index 5 to 1 etc...)

----------------------------------------------------------------------------------------------------------------------
Author: Jim Walker
Date: 2022-05-11 12:21:55.000000000
Message: 
Patch Set 5:

(2 comments)
Line:28, /COMMIT_MSG -> Also need to understand what the sample really means - if we have to generate indexes, can there be repeats? I'm sure today when CBO uses getRandomKey it must handle duplicates and does that matter?

File Comment: /PATCHSET_LEVEL -> Are there any other problems in this commit? As most of the churn is API changes I'd like to create an issue to track the "random" aspect and push this forward as is.

I've got some questions over to Marco to help understand what the sampling should look like and a subsequent change could address your concerns.
----------------------------------------------------------------------------------------------------------------------
Author: Jim Walker
Date: 2022-05-11 12:30:47.000000000
Message: 
Patch Set 5:

(1 comment)
File Comment: /PATCHSET_LEVEL -> https://issues.couchbase.com/browse/MB-52089 for tracking a better sample
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-05-11 12:47:06.000000000
Message: 
Patch Set 5:

(2 comments)
Line:28, /COMMIT_MSG -> Yes, if it's using getRandomKey that already has the possibility of dupes.

From that pov I'd say we don't need to care about duplicates here, we should just generate a random set of numbers, sort and walk the range stopping at those samples I think.

File Comment: /PATCHSET_LEVEL -> I only looked as far as the commit message for the approach used. 

If changing the sampling algorithm wouldn't change the approach / implementation that much I can look at the rest of the code, but if it does change then probably worth waiting until that's been resolved.
----------------------------------------------------------------------------------------------------------------------
Author: Jim Walker
Date: 2022-05-11 14:23:35.000000000
Message: 
Patch Set 5:

(1 comment)
File Comment: /PATCHSET_LEVEL -> Not a lot changes - most of the code here is the API change - allowing the sampling mode to be enabled and setting of the seed and sample size.

I think the internal RangeScan API looks the same too, just how we determine what to skip and what to include changes
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-05-11 14:25:39.000000000
Message: 
Patch Set 5: -Code-Review

(1 comment)
File Comment: /PATCHSET_LEVEL -> Ack. I'll try to review later today.
----------------------------------------------------------------------------------------------------------------------
Author: Jim Walker
Date: 2022-05-12 12:19:47.000000000
Message: 
Patch Set 5:

(1 comment)
File Comment: /PATCHSET_LEVEL -> I'm still discussing with Bingjie about changing the internal key sample algo. 

An idea which avoids pre-calculating and sorting random numbers (which could be a huge number of indexes to hold onto) is maybe use std::discrete_distribution

If the API for this says "sample me approx 5% of the keys", I could use std::discrete_distribition(95, 5)

I.e. return 0, 95% of the time and 1 5% of the time. scan through the index and include keys when I get a 1 from the distribution

This leads to say 490 keys of a 10k dataset, not a perfect 500, just need to find out if this is suitable in that respect. If so, I think it also satisfies the bias? Allowing for k0,k1 in the example 

Although in reality a very small dataset we may sample nothing as the distribution may return 0 for all 9 keys (include nothing), but larger datasets are ok
----------------------------------------------------------------------------------------------------------------------
Author: Jim Walker
Date: 2022-05-12 12:47:51.000000000
Message: 
Patch Set 5:

(1 comment)
File Comment: /PATCHSET_LEVEL -> ignore above, still quite biased :D
----------------------------------------------------------------------------------------------------------------------
Author: Jim Walker
Date: 2022-05-12 13:06:33.000000000
Message: 
Patch Set 5:

(1 comment)
File Comment: /PATCHSET_LEVEL -> maybe bernoulli_dist set to generate true samples/collection-size times, seems ok in a test, still can generate < samples
----------------------------------------------------------------------------------------------------------------------
Author: Jim Walker
Date: 2022-05-16 13:18:01.000000000
MISMATCHED INLINE COMMENT
Line:28, /COMMIT_MSG -> Latest patch changes the core generation, API still the same
----------------------------------------------------------------------------------------------------------------------
