======================================================================================================================
DESCRIPTION:

MB-49489: Add Magma bloom filter memory quota

Currently magma's bloom filters use ~1 byte per key
and can't be evicted. They are accounted for in sizing magma's
write cache and block cache ie. if bloom filters exceed the
10% magma memory quota, block cache quota is set to zero and
write cache will only store one batch at a time.

At very low dgm, it is possible for the bloom filters
to consume a significant proportion of the bucket memory
quota. If we have lots of small items, it can result in a case
where bloom filters consume most of the bucket memory quota
before we hit the 1% dgm mark and we hang.

This change adds an additional bloom filter quota after
which magma will start permanent background eviction of
the bloom filters. This will significantly affect performance
and should only kick in to avoid hanging. The quota is set
to 40% of the bucket quota to prevent the hang, in tests
we found that we hang once the bloom filter memory usage
reaches around 75% of quota.

Change-Id: I0d9ae750ab254e8c837cfd9157912bb1d37cfcc4

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Apaar gupta
Date: 2022-02-09 20:34:28.000000000
Message: 
Uploaded patch set 3.
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2022-02-09 20:56:24.000000000
Message: 
Patch Set 3: Verified-1

Build Failed 

http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/43747/ : FAILURE

Failure of GoogleTest "PersistentAndEphemeral/StreamTest.test_streamIsKeyOnlyTrue/ephemeral":

<pre>
[ RUN      ] PersistentAndEphemeral/StreamTest.test_streamIsKeyOnlyTrue/ephemeral
unknown file: error: C++ exception with description "cb::io::rmrf: remove of file \\?\C:\Jenkins\workspace\kv_engine-windows-master\build\kv_engine\ep_engine_ep_unit_tests.db\test.423404\nexus-secondary\magma.0\wal\wal.1 under ep_engine_ep_unit_tests.db/test.423404 failed: The data is invalid." thrown in TearDown().
[  FAILED  ] PersistentAndEphemeral/StreamTest.test_streamIsKeyOnlyTrue/ephemeral, where GetParam() = "ephemeral" (24 ms)
PersistentAndEphemeral/StreamTest.test_streamIsKeyOnlyTrue/ephemeral
</pre>
 ( http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/43747/ )

Failure of an engine_testapp test:

<pre>
Running [0139/0159]: test eviction with xattr...(16 ms) SKIPPED


99% tests passed, 3 tests failed out of 421

Total Test time (real) = 674.67 sec

The following tests FAIL
</pre>
 ( http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/43747/ )

Timeout of a CTest test 420/421 Test #289: ep_testsuite_dcp.full_eviction.comp_active ....................................................................................} ( http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/43747/ )

http://cv.jenkins.couchbase.com/job/kv_engine-clang_format_9/14313/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_tidy-master/15469/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/36908/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/5119/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/17508/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/5177/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/16286/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/17200/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/18246/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/25607/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2022-02-09 21:19:25.000000000
Message: 
Patch Set 3: Verified+1

Build Successful 

http://cv.jenkins.couchbase.com/job/kv_engine-clang_format_9/14313/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_tidy-master/15469/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/36908/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/5119/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/17508/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/5177/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/16286/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/17200/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/18246/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/25607/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/43748/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-02-10 09:26:22.000000000
Message: 
Patch Set 3: Code-Review-1

(1 comment)
Line:1329, engines/ep/configuration.json -> Magma already has a given percentage of the overall Bucket quota (magma_mem_quota_ratio). Any Bloom filter quota which Magma wants to impose needs to come out of it's existing quota - i.e. this needs to be say 0.4x of  magma_mem_quota_ratio; not of the overall Bucket quota.

----------------------------------------------------------------------------------------------------------------------
Author: Apaar gupta
Date: 2022-02-10 11:43:41.000000000
Message: 
Patch Set 3:

(1 comment)
Line:1329, engines/ep/configuration.json -> Bloom filters cannot be accounted for as part of magma's memory quota since they grow with the number of keys, i think it is similar with couchstore. This quota does not kick in unless we are at very low dgm and with very tiny keys ie. a state where magma is already exceeding the 10% quota given. Magma's memory sizing takes into account bloom filter size and if the bloom filter size starts to exceed the magma memory quota, the block cache is disabled and the write cache only cache's a single batch at a time.

The case we are trying to mitigate with this quota is very low dgm where the number of keys is very high and the bloom filters eventually fill up the entire bucket memory quota causing us to hang. At lower dgm(around 1-2%), the magma quota of 10% is too low. If we make it 40% of that quota, it will result in us having almost no data in bloomfilters. Without bloomfilters, performance basically falls off a cliff.

----------------------------------------------------------------------------------------------------------------------
Author: Apaar gupta
Date: 2022-02-10 11:56:33.000000000
Message: 
Patch Set 3:

(1 comment)
Line:1329, engines/ep/configuration.json -> For eg with 1B items at 1024 bytes each ie. 1TB of data, the bloom filters alone consume 1GB(10%) of the 10GB bucket quota needed to achieve 1% dgm.

----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-02-10 12:09:02.000000000
Message: 
Patch Set 3:

(1 comment)
Line:1329, engines/ep/configuration.json -> Growing with keys is arguably the same as the rest of Magma's memory usage.

If you want to change memory quota for Magma that's fine, but it doesn't get *two* quotas, it gets one then decides how it wants to manage it.

Note that our workloads are typically typically read-heavy and hence we want to set the default memory assignment to mostly cache hot items in memory - so the default memory quotas should be set to that (currently Magma gets 10% of the Bucket).

If certain use-cases work better with Magma having more memory assigned (write-heavy / heavy DGM ratio), then we should expose a single setting for the user - say increase `magma_mem_quota_ratio` to 20%, 50* or maybe even 80%. 

*But* - the user shouldn't have to juggle two settings (magma_mem_quota_ratio and magam_bloom_filter_mem_quota_ratio) - that's a problem for us to solve.

----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-02-10 12:15:17.000000000
Message: 
Patch Set 3:

(1 comment)
Line:1329, engines/ep/configuration.json -> > For eg with 1B items at 1024 bytes each ie. 1TB of data, the bloom filters alone consume 1GB(10%) of the 10GB bucket quota needed to achieve 1% dgm

Indeed - which I believe is why you are making them pagable ;)

If that particular use-case benefits from having more of the Bloom filters in memory, then the solution would be to increase `magma_mem_quota_ratio` (and Magma can decide exactly how much of it's overall quota it wants to assign to Bloom filters).

----------------------------------------------------------------------------------------------------------------------
Author: Apaar gupta
Date: 2022-02-10 12:30:39.000000000
Message: 
Patch Set 3:

(1 comment)
Line:1329, engines/ep/configuration.json -> The current bloom filter eviction is permanent, it is only meant to kick in when the only other option is magma consuming all the bucket quota and hanging the system. Once evicted the sstable's bloom filter cannot be bought back into memory unless the sstable is compacted. We went with this approach cos it was simple and we did not want to risk regressions in Neo.

The plan in Morpheus is to make the bloom filters paged(basically each sstable has a bunch of tiny bloom filters) and run them through an LRU. This requires us to first improve our bloom filters with optimisations for lower carnality followed by changes to the sstable to tie the smaller filters to sub-ranges of the sstable and then adding in an LRU. When that is implemented we will mostly get rid of this quota since the LRU's sizing will be done similar to what the block cache currently uses.

----------------------------------------------------------------------------------------------------------------------
Author: Apaar gupta
Date: 2022-02-10 12:41:17.000000000
Message: 
Patch Set 3:

(1 comment)
Line:1329, engines/ep/configuration.json -> Btw the problem of giving magma more memory at lower dgm is also a complicated one. Cos in a random workload magma should ideally get a larger chunk but if it is a hot-cold workload(say the user is operating on 10Gb of their 1TB bucket), kv should get more memory.

----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-02-10 13:14:11.000000000
Message: 
Patch Set 3:

(1 comment)
Line:1329, engines/ep/configuration.json -> > The current bloom filter eviction is permanent, it is only meant to kick in when the only other option is magma consuming all the bucket quota and hanging the system. Once evicted the sstable's bloom filter cannot be bought back into memory unless the sstable is compacted. We went with this approach cos it was simple and we did not want to risk regressions in Neo.

That's going to give a really poor user experience - if they "happen" to blow the limit (maybe the user dropped the bucket quota when experimenting, maybe they had a bulk operation once which increased usage temporarily), they could loose all their Bloom filters and their performance would (I assume) be terrible until they rebooted all their nodes - which is not a simple thing for most use-cases.

In terms of "risk regressions" - I think the approach you have now will introduce /more/ performance regressions if Magma happens to trip this new "emergency dump" flag.

---

Basically we want to obey the principle of least surprise here - if a user ends up storing "too much" data into a Magma bucket - what do we want to happen?

A. The bucket drops all it's Bloom filters, disk-related performance craters and they have to reboot all nodes to fix it (after performing some kind of remedial work like adjust quotas / delete old data), or say

B. The user gets some feedback that they have hit a limit, but current behaviour is unchanged (they still have their needed Bloom filters), and they have the chance to perform some online remedial operation.

If we are saying for Magma (in Neo) that a certain amount of memory is required for Bloom filters for correct operation, I think we are probably better off making that explicit - i.e. tell people they need 1 Byte per key of Bucket quota, and account the Magma Bloom filters against magma_mem_quota_ratio; then apply suitable back pressure if the Bloom filters get too big (probably start returning tmpOOM).

That gives the user the ability to control the behaviour - if they see that Magma has run out of Bloom filter memory they can choose to increase the amount of memory they give to Magma (magma_mem_quota_ratio), or perhaps delete items etc.

One Q on that: Would (full) compaction potentially reduce Bloom filter memory usage (as we'd merge possible duplicate keys, etc)?


(The Morpheus plan seems a good one btw.)

> Btw the problem of giving magma more memory at lower dgm is also a complicated one. Cos in a random workload magma should ideally get a larger chunk but if it is a hot-cold workload(say the user is operating on 10Gb of their 1TB bucket), kv should get more memory.

Yes and no - the idea of Magma having it's own quota from the Bucket quota was Magma was free to allocate that however it chose - but still "reserving" the non-Magma memory for general object caching etc. 

The "ideal" approach (which we can discuss further for Morpheus etc) would be to have a unified cache / LRU across the Bucket, which both disk pages and documents would be stored in, and some kind of suitable weighting for say a hit on a Bloom filter vs a hit on a cached Document. Then the access pattern would dictate what objects would be cached and what would be discarded.

----------------------------------------------------------------------------------------------------------------------
Author: Apaar gupta
Date: 2022-02-10 14:54:31.000000000
Message: 
Abandoned
----------------------------------------------------------------------------------------------------------------------
