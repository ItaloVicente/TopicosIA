======================================================================================================================
DESCRIPTION:

Add new feature: UnorderedExecution

From the documentation:

`UnorderedExecution` - The client allows the server to reorder the
execution of commands (and send the responses in any order back to
the client). Note that when UnorderedExecution is selected, the
client cannot switch buckets (to make it deterministic which bucket
the operation is executed. The current proposal does not include any
barriers or other synchronization primitives.).

Change-Id: Ic3b93244d10ce09bef15c5c3596ca00af0dc9631

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Trond Norbye
Date: 2017-09-08 07:51:48.000000000
Message: 
Uploaded patch set 5.
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2017-09-08 08:09:46.000000000
Message: 
Patch Set 5: Verified+1

Build Successful 

http://cv.jenkins.couchbase.com/job/kv_engine-addresssanitizer-master/2399/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-linux-master/2476/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/2489/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/2248/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_format/1027/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-threadsanitizer-master/2519/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2017-09-08 08:50:47.000000000
Message: 
Patch Set 5: Code-Review-1

Do you have any writeup of the design for this?

I would expect we'll need the ability to opt-in to OoO on a per request basis, or alternatively the ability to specify a "request barrier" (cf. memory barrier in OoO CPU execution). 

That brings the question of if we have strong or weak request ordering, and exactly how strong - do any operations (e.g. SELECT_BUCKET) issue a full request barrier? Are all mutations ordered, but lookups can be reordered with respect to each other?

I think there's a bunch of considerations here (which likely should be discussed with the SDK team) so we have a consistent view on how to proceed.
----------------------------------------------------------------------------------------------------------------------
Author: Trond Norbye
Date: 2017-09-08 09:05:03.000000000
Message: 
Patch Set 5:

> Do you have any writeup of the design for this?

I guess I should add a new file in docs to describe it... 

 > 
 > I would expect we'll need the ability to opt-in to OoO on a per
 > request basis, or alternatively the ability to specify a "request
 > barrier" (cf. memory barrier in OoO CPU execution).

Actually it is a lot simpler than that :) It is on / off.. when enabled the server may do whatever it want, when its off all commands needs to be executed in the same order. The "use case" from the discussion I've been having with Matt and others in the SDK team is when you have individual actors which run separate dialogs with the server where we want to be able to share the same connection.



 > 
 > That brings the question of if we have strong or weak request
 > ordering, and exactly how strong - do any operations (e.g.
 > SELECT_BUCKET) issue a full request barrier? Are all mutations
 > ordered, but lookups can be reordered with respect to each other?
 > 
 > I think there's a bunch of considerations here (which likely should
 > be discussed with the SDK team) so we have a consistent view on how
 > to proceed.

To follow the design principle in memcached, this sounds too complex to solve in the server, let the client deal with it. The current workaround for all of these things is that you can always open up a second connection where you perform all of the ops you needs to have executed in a given order.
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2017-09-08 09:15:40.000000000
Message: 
Patch Set 5: Code-Review+2

> > Do you have any writeup of the design for this?
 > 
 > I guess I should add a new file in docs to describe it...
 > 
 > >
 > > I would expect we'll need the ability to opt-in to OoO on a per
 > > request basis, or alternatively the ability to specify a "request
 > > barrier" (cf. memory barrier in OoO CPU execution).
 > 
 > Actually it is a lot simpler than that :) It is on / off.. when
 > enabled the server may do whatever it want, when its off all
 > commands needs to be executed in the same order. The "use case"
 > from the discussion I've been having with Matt and others in the
 > SDK team is when you have individual actors which run separate
 > dialogs with the server where we want to be able to share the same
 > connection.
 > 
 > 
 > 
 > >
 > > That brings the question of if we have strong or weak request
 > > ordering, and exactly how strong - do any operations (e.g.
 > > SELECT_BUCKET) issue a full request barrier? Are all mutations
 > > ordered, but lookups can be reordered with respect to each other?
 > >
 > > I think there's a bunch of considerations here (which likely
 > should
 > > be discussed with the SDK team) so we have a consistent view on
 > how
 > > to proceed.
 > 
 > To follow the design principle in memcached, this sounds too
 > complex to solve in the server, let the client deal with it. The
 > current workaround for all of these things is that you can always
 > open up a second connection where you perform all of the ops you
 > needs to have executed in a given order.

Maybe this is ok to begin with, but CPU architecture history has taught us that weakly-ordered architectures have lost out to stronger-ordered ones as the effort required by the user (aka client here) to make efficient use of OoO resulted in weakly-ordered being too complex to get right / fast.

Clearly we /can/ introduce a "request barrier" command later; but I honestly think we'll end up needing such a thing for a performant, efficient and correct implementation; and as such we should at least consider what memory model we want to have. Personally I don't think "maximum weak" is a good model...
----------------------------------------------------------------------------------------------------------------------
Author: Trond Norbye
Date: 2017-09-08 09:25:15.000000000
Message: 
Patch Set 5:

> > > Do you have any writeup of the design for this?
 > >
 > > I guess I should add a new file in docs to describe it...
 > >
 > > >
 > > > I would expect we'll need the ability to opt-in to OoO on a per
 > > > request basis, or alternatively the ability to specify a
 > "request
 > > > barrier" (cf. memory barrier in OoO CPU execution).
 > >
 > > Actually it is a lot simpler than that :) It is on / off.. when
 > > enabled the server may do whatever it want, when its off all
 > > commands needs to be executed in the same order. The "use case"
 > > from the discussion I've been having with Matt and others in the
 > > SDK team is when you have individual actors which run separate
 > > dialogs with the server where we want to be able to share the
 > same
 > > connection.
 > >
 > >
 > >
 > > >
 > > > That brings the question of if we have strong or weak request
 > > > ordering, and exactly how strong - do any operations (e.g.
 > > > SELECT_BUCKET) issue a full request barrier? Are all mutations
 > > > ordered, but lookups can be reordered with respect to each
 > other?
 > > >
 > > > I think there's a bunch of considerations here (which likely
 > > should
 > > > be discussed with the SDK team) so we have a consistent view on
 > > how
 > > > to proceed.
 > >
 > > To follow the design principle in memcached, this sounds too
 > > complex to solve in the server, let the client deal with it. The
 > > current workaround for all of these things is that you can always
 > > open up a second connection where you perform all of the ops you
 > > needs to have executed in a given order.
 > 
 > Maybe this is ok to begin with, but CPU architecture history has
 > taught us that weakly-ordered architectures have lost out to
 > stronger-ordered ones as the effort required by the user (aka
 > client here) to make efficient use of OoO resulted in
 > weakly-ordered being too complex to get right / fast.
 > 
 > Clearly we /can/ introduce a "request barrier" command later; but I
 > honestly think we'll end up needing such a thing for a performant,
 > efficient and correct implementation; and as such we should at
 > least consider what memory model we want to have. Personally I
 > don't think "maximum weak" is a good model...

I'm open to discuss this (and introduce barrier commands (alternatively consume unused bits in the datatype (yes it does feel wrong to steal from there)). I think it would be nice to start with walking before running... 

One thing I'm a bit afraid of is to block experimenting with reordering commands because we want to build a too advanced system. What I'm thinking currently is to start migrating the "per command" stuff we currently hold in the connection object over to the cookie object... With that in place we'll try to parse the entire input read buffer after we've read it off the socket and execute all of them in sequence (just to know that it works as well)...  and then finally move over to a model where we allow to continue to the next one if the first one returns ewouldblock.. 

Personally I'm thinking this mode as fully experimental initially as I want us to have a ton of testing in place before we start running this on customers site... 

Adding barriers doesn't seem like a big problem later on (define what we think we want, add a new hello flag and allow for reordering the input cookie pipe (and potentially block it))
----------------------------------------------------------------------------------------------------------------------
