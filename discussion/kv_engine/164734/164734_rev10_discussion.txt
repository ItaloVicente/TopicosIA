======================================================================================================================
DESCRIPTION:

MB-47451: Avoid FollyExecutorPool::schedule/cancel use-after-free race

Scenario: A use-after-free can occur when the asynchronous task deletion
(which runs on a NonIO thread) is executed _after_ the task has already
been re-scheduled.
Specifically the following sequence of calls across threads - note
numbering indicates logical order of the 6 steps, but vertical position
indicates when tasks _actually_ are executed temporally:

  IO (futurePool) thread               CPU (NonIO) thread
  ----------------------               ------------------
  1. scheduleTask()
  2. cancelTask()
     calls resetTaskPtrViaCpuPool()
     - enqueue work on NonIO
       thread to reset GlobalTask
       shared_ptr.
  4. scheduleTask()
  5. cancelTask()
     (same as step 2).

                                       3. <<enqueued at 2>>
                                          call resetTaskPtrViaCpuPool
                                          lamba
                                          - Reset GlobalTaskShared ptr
                                          - enqueue work on futurePool
                                            to remove Proxy from
                                            taskOwners.

                                       6. <<enqueued at 2>>
                                          call resetTaskPtrViaCpuPool
                                          lamba
                                          - Reset GlobalTaskShared ptr
                                          - enqueue work on futurePool
                                            to remove Proxy from
                                            taskOwners.
                                          *** user-after-free of Proxy
                                          ***

The use-after-free occurs during the second resetTaskPtrViaCpuPool
lambda (6) is executing; as we are essentially re-freeing the Proxy
which was freed at (3). This is because the code assumes that (6) will
be executed after (4) - when a new Proxy would normally be created.

Note that we don't currently see any failure at (4) - where we are
logically re-using the same proxy (it's not yet deleted at (3) as one
might expect) - as that is a "valid" scenario as per the changes made for
MB-42029 which allow a TaskProxy to be re-used if a task is re-scheduled
before the cancel cleanup is completed.

The above scenario highlights that the fix for MB-42029 (and allowing
reuse of TaskProxy objects) is flawed :(

Solution:

Keep the reset of GlobalTask on the CPU background thread, but erase
(and delete) the TaskProxy from taskOwners immediately during
cancel. This means that we don't re-use the same TaskProxy at (4) from
(2); and hence avoid the use-after-free which previoulsy occurred at
(6). This also means that TaskProxy objects are no longer re-used,
which arguabely simplifies the model.

One small subtlety here is that this potentially opens up a new
variant of the above race - the GlobalTask being deleted on the
background CPU pool could happen _after_ the Taskable has been
unregistered; given we remove the TaskProxy immediately and hence the
existing check in unregisterTaskable that the taskable has zero
TaskProxy's registered is insufficient. To address this we _also_
track the count of Tasks which are pending reset, and include that
count when waiting for all Tasks associated with a Taskable to be
cleaned up.

See also: "MB-42029: FollyExecPool: Wait for tasks cancelled in unregisterTaskable" (c370cd5)

Change-Id: I3f8401d7ddd34ed8ca96cb8a446fd6d439074027
Reviewed-on: http://review.couchbase.org/c/kv_engine/+/164734
Tested-by: Build Bot <build@couchbase.com>
Reviewed-by: Trond Norbye <trond.norbye@couchbase.com>

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Dave Rigby
Date: 2021-11-11 09:41:15.000000000
Message: 
Change has been successfully cherry-picked as 5269e518b62aeacad9106161a8978a2d478e458e by Dave Rigby
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2021-11-11 09:41:29.000000000
Message: 
Patch Set 10:

Build Started http://cv.jenkins.couchbase.com/job/kv_engine-post-commit-master/9467/ (1/2)
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2021-11-11 09:41:30.000000000
Message: 
Patch Set 10:

Build Started http://cv.jenkins.couchbase.com/job/kv_engine-post-commit-TSan-master/6233/ (2/2)
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2021-11-11 10:09:31.000000000
Message: 
Patch Set 10:

Build Unstable 

http://cv.jenkins.couchbase.com/job/kv_engine-post-commit-master/9467/ : UNSTABLE

ERROR: rebalance_in_with_ops (rebalance.rebalancein.RebalanceInTests)
 ( http://cv.jenkins.couchbase.com/job/kv_engine-post-commit-master/9467/ )

http://cv.jenkins.couchbase.com/job/kv_engine-post-commit-TSan-master/6233/ : UNSTABLE

Failure of a testrunner test ( http://cv.jenkins.couchbase.com/job/kv_engine-post-commit-TSan-master/6233/ )

ERROR: do_warmup_100k (memcapable.WarmUpMemcachedTest)
 ( http://cv.jenkins.couchbase.com/job/kv_engine-post-commit-TSan-master/6233/ )'
----------------------------------------------------------------------------------------------------------------------
