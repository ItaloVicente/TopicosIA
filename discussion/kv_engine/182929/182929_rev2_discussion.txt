======================================================================================================================
DESCRIPTION:

MB-54591: ActiveStream: Avoid lost wakeup due to race on itemsReady

+Summary+

There exists a race in ActiveStream between a notifying that a new
mutation available, and processing the previous mutation(s). If the
notification occurs just before ActiveStream sets a flag indicating
that there's currently no more items to process, then the notification
is lost and the DCP stream is not notified of this new mutation when
it should be.

This results in the DCP stream being behind by that seqno, until the
the next mutation on the vBucket occurs with will re-notify the stream
and cause it to process both.

+Impact+

When it occurs, this bug introduces additional latency between a
mutation occurring on the KV node, and it getting passed to the
affected DCP client. For DCP connections which require a "current" set
of seqnos to proceed - e.g. GSI when using request_plus queries, this
can manifest as those operations hanging.

Note the latency added is bounded by the mutation rate on the vBucket
- the next mutation is guaranteed to wake up the stream (as it is now
idle and there's no possible race). For workloads with moderate
mutation rates (e.g. 1000 mutations per second per Bucket), the
additional latency on average should be 1s. However for workloads with
very low mutation rates (<100 per second) then on average the latency
would be 10+ seconds.

For workloads which are intermittent and idle for extended periods,
the added latency could be large - as long as it takes for that
vBucket to be modified again.

+Details+

The race is between the itemsReady flag being tested in
notifyStreamReady, and clearing itemsReady when there are no more
items available for the stream in ActiveStream::next(). Flag is tested
here:

    void ActiveStream::notifyStreamReady(bool force, DcpProducer* producer, uint64_t seqno) {
        bool inverse = false;
        if (force || itemsReady.compare_exchange_strong(inverse, true)) {

            if (seqno) {
                itemsReadySeqnosForNotify.lock()->push_back(seqno);
            }
    ...

And it is set/reset here:

    std::unique_ptr<DcpResponse> ActiveStream::next(DcpProducer& producer) {
        std::unique_ptr<DcpResponse> response;
        switch (state_.load()) {
        ...
        case StreamState::InMemory:
            response = inMemoryPhase(producer);
            break;
        ...
        }

       itemsReady.store(response ? true : false);
       return response;
   }

We can lose a notification (from ActiveStream::notifyStreamReady) from
one front-end thread (performing a set) if the notification occurs
while the DCP thread is executing ActiveStream::next() and has already
called inMemoryPhase() and found the CheckpointManger empty - but
*before* we clear itemsReady at the end of the function.

To fix the lost wakeup we clear itemsReady _before_ we fetch the next
response - and only set it back to true (inhibiting notifies) if we
find we have at least one more item.

This potentially swaps lost wakeups for unnecessary wakeups (i.e. if a
notifyStreamReady() occurs in ActiveStream::next() between clearing
itemsReady and re-setting it at the end) - but correctness >
performance.

Change-Id: I3ed9ff1abfe654b8ced4e9c8d084bd0ddaa668ee

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Dave Rigby
Date: 2022-11-18 09:48:55.000000000
Message: 
Uploaded patch set 2.
----------------------------------------------------------------------------------------------------------------------
Author: Restriction Checker
Date: 2022-11-18 09:49:09.000000000
Message: 
Patch Set 2: Well-Formed-1

Branch restricted. PLEASE READ this URL: 

https://server.jenkins.couchbase.com/job/restricted-branch-check/325438/artifact/restricted.html : FAILURE
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2022-11-18 10:33:43.000000000
Message: 
Patch Set 2: Verified+1

Build Successful 

https://cv.jenkins.couchbase.com/job/kv_engine-windows-madhatter/2332/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-mad-hatter/2085/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine-clang_format/26701/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/mad-hatter/235/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/mad-hatter/1964/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine.macos/job/mad-hatter/1533/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/mad-hatter/2183/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/mad-hatter/2169/ : SUCCESS

https://cv.jenkins.couchbase.com/job/kv_engine.linux/job/mad-hatter/2183/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-11-21 09:36:19.000000000
Message: 
Patch Set 2:

(1 comment)
File Comment: /PATCHSET_LEVEL -> check approval
----------------------------------------------------------------------------------------------------------------------
Author: Restriction Checker
Date: 2022-11-21 09:36:33.000000000
Message: 
Patch Set 2: Well-Formed+1

Permission granted to commit: 

https://server.jenkins.couchbase.com/job/restricted-branch-check/325685/artifact/restricted.html : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Ben Huddleston
Date: 2022-11-21 10:07:47.000000000
Message: 
Patch Set 2: Code-Review-1

(6 comments)
Line:141, engines/ep/src/dcp/stream.h -> and next()

Line:2930, engines/ep/tests/module_tests/dcp_stream_test.cc -> A few of the tests in this file (on neo at least) use MockDCPConnMap. Might be simple enough/less to explain if you use it here

Line:2946, engines/ep/tests/module_tests/dcp_stream_test.cc -> start and end seqnos? The InSequence stuff is pretty nice here, but not obvious to understand what the numbers mean

Line:2949, engines/ep/tests/module_tests/dcp_stream_test.cc -> seqno?

Line:2969, engines/ep/tests/module_tests/dcp_stream_test.cc -> nit: empty comment line

Line:2990, engines/ep/tests/module_tests/dcp_stream_test.cc -> which means that prior to the fix we would fail to "runNextTask"?

----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2022-11-21 10:47:04.000000000
Message: 
Patch Set 2: Code-Review+2

(2 comments)
Line:192, engines/ep/src/dcp/active_stream.cc -> As you nicely reported in the commit message, nice to add a note here on that some unnecessary wakeups might occur

Line:2930, engines/ep/tests/module_tests/dcp_stream_test.cc -> Just for reference, alternatively I believe you can go via:
1. producer->streamRequest (will add stream to ConnMap)
2. stream = ConnMap::findStream

----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-11-21 10:51:08.000000000
Message: 
Patch Set 2:

(7 comments)
Line:192, engines/ep/src/dcp/active_stream.cc -> Done

Line:141, engines/ep/src/dcp/stream.h -> Done

Line:2930, engines/ep/tests/module_tests/dcp_stream_test.cc -> Good spot - will adjust.

@paolo: I need to access the readyQ to confirm the producer was notified, so need to use the mock stream.

Line:2946, engines/ep/tests/module_tests/dcp_stream_test.cc -> Done

Line:2949, engines/ep/tests/module_tests/dcp_stream_test.cc -> Done

Line:2969, engines/ep/tests/module_tests/dcp_stream_test.cc -> Done

Line:2990, engines/ep/tests/module_tests/dcp_stream_test.cc -> Done

----------------------------------------------------------------------------------------------------------------------
