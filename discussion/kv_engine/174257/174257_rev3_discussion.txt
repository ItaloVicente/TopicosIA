======================================================================================================================
DESCRIPTION:

MB-50984: Remove chk_period

The param was used for enforcing checkpoint creation on a time-base.
What we want instead is being mem-usage driven on checkpoint creation.

Change-Id: Icaa578e35f41d50559b71c2a1eb687479a1a153a

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Paolo Cocchi
Date: 2022-04-29 08:44:25.000000000
Message: 
Uploaded patch set 3.
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2022-04-29 09:27:53.000000000
Message: 
Patch Set 3: Verified-1

Build Failed 

http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/27355/ : FAILURE

Compile error at [2022-04-29T08:46:49.941Z] ../kv_engine/engines/ep/src/configuration.h:185:10:
fatal error: "generated_configuration.h" file not found
 ( http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/27355/ )

http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/18101/ : FAILURE

Failure of an engine_testapp test:

<pre>
Running [42/160]: file stats post warmup...../kv_engine/engines/ep/tests/ep_testsuite.cc:2324 Test failed: `" (Expected `383386" to be less than or equal to `368640" - Unexpected fileSize for vbucket)
[2022-04-29T09:18:24.017Z] (281 ms) FAIL
</pre>
 ( http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/18101/ )

http://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/38483/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_tidy-master/17183/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/45818/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_format_9/16145/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/6901/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/6809/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/19289/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/18951/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/19980/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2022-04-29 15:11:58.000000000
Message: 
Patch Set 3:

Build Failed 

http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/18131/ : FAILURE

No problems were identified. If you know why this problem occurred, please add a suitable Cause for it. ( http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/18131/ )

http://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/38483/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_tidy-master/17183/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/45818/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_format_9/16145/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/6901/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/6809/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/19289/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/18951/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/19980/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/27372/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2022-04-29 17:36:35.000000000
Message: 
Patch Set 3: Verified+1

Build Successful 

http://cv.jenkins.couchbase.com/job/kv_engine-clang_analyzer-master/38483/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_tidy-master/17183/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-windows-master/45818/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine-clang_format_9/16145/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.aarch64-linux/job/master/6901/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.libFuzzer/job/master/6809/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux/job/master/19289/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.linux-CE/job/master/18951/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.threadsanitizer/job/master/19980/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.ASan-UBSan/job/master/27372/ : SUCCESS

http://cv.jenkins.couchbase.com/job/kv_engine.macos/job/master/18134/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-05-05 09:08:03.000000000
Message: 
Patch Set 3:

(1 comment)
File Comment: /PATCHSET_LEVEL -> Are there any scenarios where we still want some form of time-based checkpoint creation - for example a two-phase workload which consists of a high throughput bulk load (causing a bunch of checkpoints to be created and consuming CkptMgr memory), then a second phase where the system goes (virtually) idle?

With chk_period, we create a new checkpoint (after 5 seconds?) which allows us to delete closed unreferenced checkpoints. If we remove chk_period then what happens in these situations?

Related to this, what testing have we done around removing this code?

----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-05-05 13:04:22.000000000
Message: 
Patch Set 3: Code-Review-1
----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2022-05-10 11:17:17.000000000
Message: 
Patch Set 3:

(1 comment)
File Comment: /PATCHSET_LEVEL -> > Are there any scenarios where we still want some form of time-based checkpoint creation .. ?

So let's consider what happens in Neo. 2 code paths where the we might hit the time trigger:

1. frontend / queueDirty
2. bg / MemRecoveryTask

Your scenario:
 - Load phase: the system will create checkpoint regardless of the time trigger - that's all based on the memory state of the system.
 - Idle phase
 
[Focus on the Idle phase]
The logic in the MemRecoveryTask is as follows
 - if mem-recovery not require, then return
 - else, maybe create a new checkpoint -> This is where the time trigger might hit, but we enter in this else-branch only if mem recovery is needed, which means that some new checkpoint (in some vb) will be created regardless from the time trigger
 
The focus is on the fact that we seem to have the mem-trigger addressing already all what we need for ensuring the "correct" behaviour on checkpint's mem management.
Also, the time trigger itself wouldn't kick if mem recovery isn't required.

Note:
It important that we agree on what is "correct". With that here I mean that checkpoint memory recovery must be driven by CMQuota/upper_mark/lower_mark. That means, if CM-usage is below the upepr_mark we don't want to release anything from checkpoints.
Even if "old", keeping some items in the checkpoint is valuable with regard to DCP - We would set checkpoint_memory_recovery_upper_mark=0 otherwise in config, right?

> Related to this, what testing have we done around removing this code?

We have extended test coverage that the mem-trigger behaves as expected.

Same as other changes in this stack, best thing would be having a full Perf scan on it.
----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2022-05-11 09:12:19.000000000
Message: 
Patch Set 3:

(1 comment)
File Comment: /PATCHSET_LEVEL -> Another thing to mention.
The CheckpointMemRecoveryTask still runs periodically every 5sec (regardless of any explicit trigger).
That doesn't mean that a checkpoint will be closed by "age", that just means that some checkpoint will be closed (and released) if mem-recovery is required (again, only driven by CMQuota and its marks)
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-05-11 10:52:26.000000000
Message: 
Patch Set 3:

(1 comment)
File Comment: /PATCHSET_LEVEL -> Sounds good. 

To summarise my understanding:

1. We only attempt to free memory (create new checkpoint to close existing and if unreferenced delete it) if we are over the CheckpointManager high watermark. 
2. As such, periodic creation of a new checkpoint via chk_period is redundant as even _if_ 5 seconds has passed since the last kept was created, we wouldn't even attempt to create one unless we were over the CkptMgr high watermark

Correct?
----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2022-05-11 12:33:52.000000000
Message: 
Patch Set 3:

(1 comment)
File Comment: /PATCHSET_LEVEL -> That's all correct with regard to the bg/CheckpointMemRecoveryTask path.

There's a difference in the fe/queueDirty path though. There the chk_period might hit regardless of the memory state - Eg when processing a SET we might create a new checkpoint only because the open one is older than chk_period (ie, checkpoint not full, CM usage not even close the upper_mark).
That's the only behaviour change here, we are essentially removing that path.
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-05-11 12:44:33.000000000
Message: 
Patch Set 3:

(1 comment)
File Comment: /PATCHSET_LEVEL -> Nod.

I can't really think of any advantage to creating a checkpoint in queueDirty if it's been chk_period seconds since the last now, given we have the other memory recovery methods.

As long as we can close any open checkpoints _if_ memory usage gets high (without there being any front-end ops to "trigger" any closing), I think we are good.
----------------------------------------------------------------------------------------------------------------------
Author: Paolo Cocchi
Date: 2022-05-11 12:55:12.000000000
Message: 
Patch Set 3:

(1 comment)
File Comment: /PATCHSET_LEVEL -> > I can't really think of any advantage to creating a checkpoint in queueDirty if it's been chk_period seconds since the last now, given we have the other memory recovery methods.

I confirm that frontend operations always do 2 things:

1. Check on the CM-mem-usage state before attempting to process the operation. That is where we might wakeup the CheckpointMemRecoveryTask
2. Check on the single checkpoint at CM::queueDirty() - If the single checkpoint if full (based on checkpoint_max_size_bytes) then we close it and create a new open one + "eager" checkpoint removal

> As long as we can close any open checkpoints _if_ memory usage gets high (without there being any front-end ops to "trigger" any closing), I think we are good.

That's exactly the logic in CheckpointMemRecoveryTask:

bool CheckpointMemRecoveryTask::runInner() {
    TRACE_EVENT0("ep-engine/task", "CheckpointMemRecoveryTask");

    auto& bucket = *engine->getKVBucket();

    if (!bucket.isCheckpointMemoryReductionRequired()) {
        return true;
    }
..

    if (attemptNewCheckpointCreation() == ReductionRequired::No) {
        // Recovered enough, done
        return true;
    }
    
..
    <other mem recovery strategies>
..
}
----------------------------------------------------------------------------------------------------------------------
Author: Dave Rigby
Date: 2022-05-11 12:56:42.000000000
Message: 
Patch Set 3: Code-Review+2

(1 comment)
File Comment: /PATCHSET_LEVEL -> Thanks for the detailed description.
----------------------------------------------------------------------------------------------------------------------
