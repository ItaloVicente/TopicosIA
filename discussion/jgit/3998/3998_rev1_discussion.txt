======================================================================================================================
DESCRIPTION:

UploadPack: Enable caching of dynamic packs

When a pack is created for a client to incrementally update itself,
there may be other clients that want to perform the exact same
incremental update. Enable saving the pack in a per-repository cache
and replaying that result when requested again by another client.

This simple cache should help servers that need to handle lots of
updates from clients where the clients are primarily fetching only
from the same server, and the repository is updated much less
frequently than clients fetch from it.

This change only adds the cache interface, but does not specify how it
should be stored or configured. One approach could be to save the pack
to memory if it is small enough, or write the file out to a cache
directory within $GIT_DIR.

Change-Id: Ie56157ca556728e046446595ba7c42e794e6bd30
Signed-off-by: Shawn O. Pearce <spearce@spearce.org>

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Shawn Pearce
Date: 2011-10-07 21:22:27.000000000
Message: 
Patch Set 1:

You are right, we can start by just logging the want/have lists from requests. Fortunately that can be done without any code changes, the PackWriter.Statistics object carries all of that information. I'll give that a try for a while and see if there is any repeated requests in the logs for one of my Android servers.
----------------------------------------------------------------------------------------------------------------------
Author: Shawn Pearce
Date: 2011-10-07 21:22:27.000000000
Message: 
Patch Set 1: I would prefer that you didn't submit this

I'm not sure about this as a feature yet. I still need to write a caching implementation and experiment to see if there are enough requests that the cache can answer faster than the brute force packing to make it worth even having in the tree. Thus far everyone on the git mailing list has said this isn't worthwhile... but nobody has run the experiments to actually see.
----------------------------------------------------------------------------------------------------------------------
Author: Robin Rosenberg
Date: 2011-10-07 21:22:27.000000000
Message: 
Patch Set 1:

You could start by just logging the currently generated packs (name size, generation time), then we can scan the logs to see how much redundant work there is.
----------------------------------------------------------------------------------------------------------------------
Author: Hudson CI
Date: 2011-10-07 21:22:27.000000000
Message: 
Patch Set 1:

Build Started https://hudson.eclipse.org/sandbox/job/jgit.gerrit/704/ 
----------------------------------------------------------------------------------------------------------------------
Author: Hudson CI
Date: 2011-10-07 21:22:27.000000000
Message: 
Patch Set 1: Build Successful

Build Successful 
 
https://hudson.eclipse.org/sandbox/job/jgit.gerrit/704/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Shawn Pearce
Date: 2011-10-07 21:22:27.000000000
Message: 
Patch Set 1: Abandoned

I tried looking at some logs from a patched Gerrit Code Review server internally at Google. I didn't see enough common request patterns to justify this change, so I'm going to abandon it for now.
----------------------------------------------------------------------------------------------------------------------
