======================================================================================================================
DESCRIPTION:

Fix for core.autocrlf=input resulting in modified file

Bug: 372834
Change-Id: Idafad150553df14827eccfde2e3b95760e16a8b6
Also-by: Robin Stocker <robin@nibor.org>

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Robin Rosenberg
Date: 2013-12-07 16:20:14.000000000
Message: 
Uploaded patch set 5.
----------------------------------------------------------------------------------------------------------------------
Author: CI Bot
Date: 2013-12-07 16:20:21.000000000
Message: 
Patch Set 5:

Build Started https://hudson.eclipse.org/egit/job/jgit.gerrit/4303/
----------------------------------------------------------------------------------------------------------------------
Author: CI Bot
Date: 2013-12-07 16:45:17.000000000
Message: 
Patch Set 5: Verified+1

Build Successful 

https://hudson.eclipse.org/egit/job/jgit.gerrit/4303/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Robin Stocker
Date: 2013-12-08 15:54:25.000000000
Message: 
Patch Set 5:

Have you seen my other 2 comments from patch set 2? The other parts look good to me now.
----------------------------------------------------------------------------------------------------------------------
Author: Christian Halstrick
Date: 2013-12-08 20:40:40.000000000
Message: 
Patch Set 5:

(1 comment)
Line:897, org.eclipse.jgit/src/org/eclipse/jgit/treewalk/WorkingTreeIterator.java -> I think that algorithm will work.

But I am wondering whether we really have no more efficient way. In this block we are reading some parts of the content 3 times. First RawText.isBinary will read the first 8 KB. Then we are reading the complete file just to compute the resulting length . And then we are finally reading it a third time, do the same EOLCanonicalization again as in the previous step to comput a SHA1 of the content.

If we would have a InputStream who would do EolCanonicalization on a arbitrary length stream we could save one round of reading the file. If that same InputStream implementation would throw an exception if he detects the file is binary we could save another round of reading the content. That would be a big performance boost I guess.

We could also do it in a different change - but I think we should fix this.

----------------------------------------------------------------------------------------------------------------------
Author: Robin Rosenberg
Date: 2013-12-09 15:42:24.000000000
Message: 
Patch Set 5:

(2 comments)
Line:897, org.eclipse.jgit/src/org/eclipse/jgit/treewalk/WorkingTreeIterator.java -> If everything is smudged, then yes it'll be performance boost.

Line:909, org.eclipse.jgit/src/org/eclipse/jgit/treewalk/WorkingTreeIterator.java -> I wonder, is there a reason not to unsmudge when we know files are different too?

----------------------------------------------------------------------------------------------------------------------
Author: Robin Rosenberg
Date: 2013-12-10 11:27:15.000000000
Message: 
Patch Set 5:

(2 comments)
Line:897, org.eclipse.jgit/src/org/eclipse/jgit/treewalk/WorkingTreeIterator.java -> Done

Line:909, org.eclipse.jgit/src/org/eclipse/jgit/treewalk/WorkingTreeIterator.java -> Done

----------------------------------------------------------------------------------------------------------------------
