======================================================================================================================
DESCRIPTION:

MB-9321 Infrastructure for new orchestration.

The two core concepts are leader activities and leader leases. The
leader activity is any task requiring a degree of coordination in the
cluster. Normally these tasks are started by the master node. In order
to provide the required safety guarantees, each activity has a quorum
attached to it. Quorum specifies a set of nodes that need to agree to
run the task. The quorum can either specify a specific set of nodes
required, or it can require a majority of nodes in a set. Or
both. Leader lease is a promise from a node to serve master's and only
master's requests for a specified amount of time. The master node will
proactively acquire these leases even when there are no activities to
run at the moment.

Brief technical overview.

 - Each node in the cluster will always run at least leader_activities
   and leader_lease_agent processes.

 - leader_lease_agent is the process that responds to master requests
   for a lease. Every time a lease is granted, it's persisted to disk,
   so that even if the process dies, when it restarts, it will
   continue honoring the lease.

 - leader_activities process keeps track of all the activities that
   are being run by the node. When a lease expires, the activities are
   terminated. Before all the activities are safely terminated, the
   lease will not be granted to other nodes.

 - In addition to the above two processes, master node is also running
   a leader_lease_acquirer. Its job is to acquire and renew the leases
   when time is up. It tries to be smart and keeps track of
   communication delays to the other nodes, so it doesn't request
   lease renewals too early.

 - Leader lease is identified by a tuple of node name and a unique
   id. The latter creates some issues (node renames are hard), but
   improves diagnosability. Whenever lease_acquirer process starts, it
   generates a fresh id for the lease. Then all the activities that
   are being started are tagged with the id. That makes sure that
   stale activity requests are rejected.

Culprits:

 - There's still a heavy reliance on ns_config, which doesn't provide
   proper consistency guarantees. To mitigate this fact, I try to make
   sure the config gets synchronized to all nodes at strategic points.

 - There's a reliance on time flowing at somewhat similar rate at
   different nodes. Which is a strong assumption. In order to lower
   the odds of related issues, the leader node will abandon its lease
   with some grace period, before the lease actually expires on the
   nodes. In addition, all the important processes are set to have
   high priority.

 - Not all safety features are used as of now. The idea is that any
   potentially dangerous activity that needs to do something at a
   particular node needs to be funneled through
   leader_activities. That would guarantee that even if things go
   wrong, another conflicting activity won't get started. Addressing
   this should also prevent most of problems stemming from the time
   issues.

Change-Id: Ia4e688f187365bf777a681bc296063ca3d8550b7

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Aliaksey Artamonau
Date: 2018-02-08 08:39:33.000000000
Message: 
Uploaded patch set 10: Patch Set 9 was rebased.
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2018-02-08 08:39:49.000000000
Message: 
Patch Set 10: -Well-Formed

Build Started http://cv.jenkins.couchbase.com/job/ns-server-test/2594/
----------------------------------------------------------------------------------------------------------------------
Author: Aliaksey Artamonau
Date: 2018-02-08 08:40:37.000000000
Message: 
Patch Set 10: Verified+1
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2018-02-08 08:54:54.000000000
Message: 
Patch Set 10: Well-Formed+1

Permission granted to commit to restricted branch
----------------------------------------------------------------------------------------------------------------------
Author: Aliaksey Artamonau
Date: 2018-02-08 09:06:52.000000000
Message: 
Removed reviewer Build Bot with the following votes:

* Well-Formed+1 by Build Bot <build@couchbase.com>

----------------------------------------------------------------------------------------------------------------------
Author: Poonam Dhavale
Date: 2018-02-08 19:08:51.000000000
Message: 
Patch Set 10:

(1 comment)
Line:242, src/leader_activities.erl -> Lease has already been set above.

----------------------------------------------------------------------------------------------------------------------
Author: Poonam Dhavale
Date: 2018-02-08 21:16:36.000000000
Message: 
Patch Set 10:

I am just thinking out loud here.

The leader_lease data that is persisted to disk stores only the time_left on the lease. This can cause some delays during certain scenarios like below.

1. Node0 is the master. leader_lease stored on disks on all nodes indicates Node0 is the lease holder. Normally, time_left will stay at 15s since the master renews the lease.
2. Node1 goes down. leader_lease on its disk says node0 is the lease holder.
3. Next, Node0 goes down. Node 2 becomes the master.
4. Node 2 now has the lease. 
5. Node1 comes up. Reads the leader_lease from the disk. This says Node0 is the lease holder. It populates its internally state accordingly.
6. Node2 tries to acquire lease from Node1 but is denied since according to Node1, Node0 has the lease. Node2 will be denied the lease till the lease expires. This will delay leader activities.

If “leader_lease” also stores the actual time stamp of when the lease was granted in addition to time_left, then when a node recovers the persisted lease it can  ignore the lease if (time granted + time left) < time now. These are stale leases which have long expired.

However, there could be other issues/race conditions with above optimization. 

May be better to keep the code as is. Because, I think, it is less risky if a node thinks that someone has a lease when they don’t than if the node throws out someone's lease when it is actually held.
----------------------------------------------------------------------------------------------------------------------
Author: Aliaksey Artamonau
Date: 2018-02-09 05:18:34.000000000
Message: 
Patch Set 10:

(1 comment)

> If “leader_lease” also stores the actual time stamp of when the lease was granted in addition to time_left, then when a node recovers the persisted lease it can  ignore the lease if (time granted + time left) < time now. These are stale leases which have long expired.

There's no guarantee that the time saved in the lease is at all comparable to the current time. So yes, there will be delays. I'm planning to do couple of things to improve the situation in some cases: save the lease not only when it's renewed, but maybe also update it while the time is ticking; save a lease with updated time left when the leader_lease_agent process is terminating.
Line:242, src/leader_activities.erl -> Indeed, thanks.

----------------------------------------------------------------------------------------------------------------------
