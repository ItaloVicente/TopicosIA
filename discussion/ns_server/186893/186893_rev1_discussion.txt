======================================================================================================================
DESCRIPTION:

Example patch of couch_docs_fragmentation calculatiion

Change-Id: I824bb985eadbd96b077fbd67d5b4bb24719602c0

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Peter Searby
Date: 2023-02-16 16:07:36.000000000
Message: 
Uploaded patch set 1.
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2023-02-16 16:07:48.000000000
Message: 
Patch Set 1:

Build Started https://cv.jenkins.couchbase.com/job/ns-server-test/34464/
----------------------------------------------------------------------------------------------------------------------
Author: Restriction Checker
Date: 2023-02-16 16:07:53.000000000
Message: 
Patch Set 1: Well-Formed-1

Branch restricted. PLEASE READ this URL: 

https://server.jenkins.couchbase.com/job/restricted-branch-check/338360/artifact/restricted.html : FAILURE
----------------------------------------------------------------------------------------------------------------------
Author: Build Bot
Date: 2023-02-16 16:17:50.000000000
Message: 
Patch Set 1: Well-Formed+1

Build Successful 

https://cv.jenkins.couchbase.com/job/ns-server-test/34464/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Abhijeeth Nuthan
Date: 2023-02-16 22:42:18.000000000
Message: 
Patch Set 1:

(2 comments)
Line:462, src/stat_names_mappings.erl -> I prefer this approach, since this way we keep couch_docs_fragmentation accurate but we don't introduce new field in pools/default/buckets/{bucketName}/stats endpoint. 
However, the calculation looks off to me. The couch_docs_data_size is calculated in this fun, see below, which is used in the original calculation.

Line:468, src/stat_names_mappings.erl -> Filesize is the denominator no?

----------------------------------------------------------------------------------------------------------------------
Author: Peter Searby
Date: 2023-02-20 17:10:27.000000000
MISMATCHED INLINE COMMENT
Line:462, src/stat_names_mappings.erl -> The pre-7.2 behaviour of this endpoint and the stats/range endpoint are not consistent, so we should choose between consistency of the values between the endpoints or consistency of the values between 7.1 and 7.2. However, neither of these options seem possible with a promQL query generated in this function, because both use a default value when the denominator is 0, which I have been unable to implement while keeping the calculation consistent.

The closest I have got is with a clamp_max call, which can bring NaN down to a specific value. However, it doesn't seem to work in this query for some reason which I have been unable to determine. Even if it could work, it would only be possible for having a default of 100, which is not consistent with the values of this endpoint pre-7.2
----------------------------------------------------------------------------------------------------------------------
Author: Peter Searby
Date: 2023-02-21 13:31:19.000000000
MISMATCHED INLINE COMMENT
Line:462, src/stat_names_mappings.erl -> I believe that I have the calculation now matching the pre-7.2 calculation, with default value 0 when the denominator is 0
----------------------------------------------------------------------------------------------------------------------
Author: Peter Searby
Date: 2023-02-20 17:10:27.000000000
MISMATCHED INLINE COMMENT
Line:468, src/stat_names_mappings.erl -> Fixed
----------------------------------------------------------------------------------------------------------------------
