======================================================================================================================
DESCRIPTION:

ss: Rework the HTNode cache

Make the cache static, so that all opened traces and their
statesystem make use of the same cache, and the same limit
keeping the memory usage to manageable levels.

Reimplement the cache as a Guava LoadingCache. This makes the
cache fully associative, and nicely abstracts the loading logic.

Change-Id: I267008c69f9d6f4ada0257dee45b2a79902b8c84
Signed-off-by: Matthew Khouzam <matthew.khouzam@ericsson.com>
Signed-off-by: Alexandre Montplaisir <alexmonthy@efficios.com>

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Alexandre Montplaisir
Date: 2016-04-14 22:24:58.000000000
Message: 
Uploaded patch set 1.
----------------------------------------------------------------------------------------------------------------------
Author: CI Bot
Date: 2016-04-14 22:25:04.000000000
Message: 
Patch Set 1:

Build Started https://hudson.eclipse.org/tracecompass/job/tracecompass-gerrit/7787/
----------------------------------------------------------------------------------------------------------------------
Author: Alexandre Montplaisir
Date: 2016-04-14 22:28:06.000000000
Message: 
Patch Set 1:

(1 comment)
Line:138, statesystem/org.eclipse.tracecompass.statesystem.core/src/org/eclipse/tracecompass/internal/statesystem/core/backend/historytree/HT_IO.java -> If necessary we could still load the node in the new cache manually.

----------------------------------------------------------------------------------------------------------------------
Author: CI Bot
Date: 2016-04-14 22:43:08.000000000
Message: 
Patch Set 1: Verified-1

Build Failed 

https://hudson.eclipse.org/tracecompass/job/tracecompass-gerrit/7787/ : FAILURE
----------------------------------------------------------------------------------------------------------------------
Author: Matthew Khouzam
Date: 2016-04-15 00:59:58.000000000
Message: 
Patch Set 1:

Let's be clear, the two patches (this and "make cache static") are performance patches, I would like to see performance impact of the other one too. I think that the other patch should be split into 3 patches:
 
1- replace cache with guava cache.
2- make cache static.
3- make cache write through.

And the impact should be observed on the three.

Thoughts? I will copy this comment on the other patch as it affects both.
----------------------------------------------------------------------------------------------------------------------
Author: Alexandre Montplaisir
Date: 2016-04-15 03:55:01.000000000
Message: 
Patch Set 1:

We want to make the cache static in any case, for obvious UX reasons, so I don't think it's worth benchmarking without that.

But agreed on the other points, to compare various implementations, whether we should write-back or not, and also we could try to gauge an optimal cache size.
----------------------------------------------------------------------------------------------------------------------
Author: CI Bot
Date: 2016-04-15 04:49:55.000000000
Message: 
Patch Set 1: -Verified

Build Started https://hudson.eclipse.org/tracecompass/job/tracecompass-gerrit/7808/
----------------------------------------------------------------------------------------------------------------------
Author: CI Bot
Date: 2016-04-15 05:46:28.000000000
Message: 
Patch Set 1: Code-Review+1

Build Successful 

https://hudson.eclipse.org/tracecompass/job/tracecompass-gerrit/7808/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Matthew Khouzam
Date: 2016-04-20 13:37:39.000000000
Message: 
Patch Set 1: Code-Review-1

I am -1ing this, because it changes too much and is a superset of the other patch  (https://git.eclipse.org/r/#/c/70600/) We can merge it after the other cache is in, but it would be very important to benchmark before and after.
----------------------------------------------------------------------------------------------------------------------
Author: Matthew Khouzam
Date: 2016-06-01 01:34:17.000000000
Message: 
Patch Set 1:

Got a chance to benchmark this?
----------------------------------------------------------------------------------------------------------------------
Author: Alexandre Montplaisir
Date: 2016-06-07 19:56:30.000000000
Message: 
Patch Set 1: Code-Review-1

(2 comments)

Needs to be rebased to latest master.
Line:29, statesystem/org.eclipse.tracecompass.statesystem.core/src/org/eclipse/tracecompass/internal/statesystem/core/backend/historytree/HT_IO.java -> we can use java.util.Objects.hash() instead

Line:84, statesystem/org.eclipse.tracecompass.statesystem.core/src/org/eclipse/tracecompass/internal/statesystem/core/backend/historytree/HT_IO.java -> Might not need to be so high, LoÃ¯c has more meaningful benchmark results.

----------------------------------------------------------------------------------------------------------------------
Author: Loic Prieur-Drevon
Date: 2016-06-08 17:19:25.000000000
Message: 
Patch Set 1: Code-Review-1

(2 comments)

Benchmark results: http://secretaire.dorsal.polymtl.ca/~lprieur/Caches.pdf
Line:82, statesystem/org.eclipse.tracecompass.statesystem.core/src/org/eclipse/tracecompass/internal/statesystem/core/backend/historytree/HT_IO.java -> Current cache uses (htio.hash + nodeSequenceNumber) as key, might be faster as it is an integer.

Line:97, statesystem/org.eclipse.tracecompass.statesystem.core/src/org/eclipse/tracecompass/internal/statesystem/core/backend/historytree/HT_IO.java -> In my testing, LinkedHashMap (the underlying structure of GuavaCache), used as a LRU cache has less overhead.

----------------------------------------------------------------------------------------------------------------------
Author: Matthew Khouzam
Date: 2016-06-08 18:59:02.000000000
Message: 
Patch Set 1:

So, our cache is now 256, does that make us all at an 85% hit rate?
----------------------------------------------------------------------------------------------------------------------
Author: Loic Prieur-Drevon
Date: 2016-06-08 20:40:07.000000000
Message: 
Patch Set 1:

That is an average on the synthetic trees in statesystem.core.tests/perf, in which most trees are far smaller than 256 nodes, save for the Horizontal and Vertical scaling...
----------------------------------------------------------------------------------------------------------------------
Author: Matthew Khouzam
Date: 2016-06-09 01:28:23.000000000
Message: 
Patch Set 1:

next question, how do the caches react under heavy parallel usage. We typically have 10-12 analyses hammering the cache simultaneously. Can the guava caches be better in that case?
----------------------------------------------------------------------------------------------------------------------
Author: Loic Prieur-Drevon
Date: 2016-06-09 12:59:34.000000000
Message: 
Patch Set 1:

Depends, if all the full queries for a series of timestamps for a SHT are done consecutively, then all the full queries for another, everything is as good as possible, else if its alternatively full queries on one tree then on another, cache eviction will be strong. 

First case, we can get away with a cache slightly bigger than the tree depth, second case, cache should be as big as sum of trees' depths.
Again, you know my thoughts on the current SHT and usage of full queries...
----------------------------------------------------------------------------------------------------------------------
Author: Loic Prieur-Drevon
Date: 2016-06-09 13:42:09.000000000
Message: 
Patch Set 1:

Ok, tried comparing an LRU cache to the current direct mapping implementation when moving around in a control flow view of one of Simon's xeon Phi trace (no. 58). 
i.e. real world traces and queries as opposed to tests/perf.

Miss ratios (on oSHT):
CacheSize    256    32      (nodes)
LRU          1.6%   3%
DM           2.5%   38%
(sorry for ugly formatting)

UI reactivity is significantly impacted too (I don't have hard numbers though).
----------------------------------------------------------------------------------------------------------------------
Author: Matthew Khouzam
Date: 2016-06-10 00:31:50.000000000
Message: 
Patch Set 1:

This is great! let's make a linkedhashmap soon as a cache.

Loic, thanks for the investigation!

To be clear, I want to highlight: 

Right now we have 256 nodes. So performance will be identical between lru and dm. lru will allow reducing to 32... which is great. I think this will avoid more lock-stepped hash collisions too. But as of this analysis, I don't think the cache needs speed updates, memory soon though if the htvarints get in.
----------------------------------------------------------------------------------------------------------------------
Author: Gerrit Code Review
Date: 2016-07-04 22:12:49.000000000
Message: 
Change has been successfully cherry-picked as 1f48ef6615540ff27fe91c838a2f5ced5fecad38 by Alexandre Montplaisir
----------------------------------------------------------------------------------------------------------------------
