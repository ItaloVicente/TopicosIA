======================================================================================================================
DESCRIPTION:

Ignore flaky unit tests

These tests fail spuriously. They should be disabled, fixed,
then brought back piece-wise. We can now use custom test suites
(like SWTStressTests.java) to detect most spurious failures.

Change-Id: Ia820861fefc528cbe07fc3d2f3cc30c13fbdb96d
Signed-off-by: Alexandre Montplaisir <alexmonthy@voxpopuli.im>

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Alexandre Montplaisir
Date: 2015-07-11 18:21:07.000000000
Message: 
Uploaded patch set 1.
----------------------------------------------------------------------------------------------------------------------
Author: CI Bot
Date: 2015-07-11 18:51:31.000000000
Message: 
Patch Set 1:

Build Started https://hudson.eclipse.org/tracecompass/job/tracecompass-gerrit/3087/
----------------------------------------------------------------------------------------------------------------------
Author: CI Bot
Date: 2015-07-11 19:20:10.000000000
Message: 
Patch Set 1: Code-Review+1

Build Successful 

https://hudson.eclipse.org/tracecompass/job/tracecompass-gerrit/3087/ : SUCCESS
----------------------------------------------------------------------------------------------------------------------
Author: Marc-André Laperle
Date: 2015-07-11 19:23:03.000000000
Message: 
Patch Set 1: Code-Review-1

The tests are not flaky on Hudson (or are they?) and they are invaluable regression tests for contributions that go through Gerrit and Hudson and its automated build. Sure it's possible that some of them don't work perfectly in some environment depending on many factors such as library versions, load, OS. If you are running a CI on such an environment that is problematic, the builds can run on a branch with those tests ignored and we can work together to improve the tests on that environment.

My main point is that the main Hudson build for the project should not IMO be affected by the lowest common denominator of environments/configurations out there. For example,
testA fails on GTK 2.12.1 but not GTK2.14.3
testB, testC fails on Mac 10.10.1 but not on 10.10.3
testD, fails on Mac 10.11.0 preview
testE fails on Windows 7 but not Windows 8.1
testF fails on GTK3.8 but not GTK3.10
testG fails on compiz but not metacity
and so on. Should test A-G be disabled for Hudson where they all work and they help developers know about regressions when they fail?
----------------------------------------------------------------------------------------------------------------------
Author: Alexandre Montplaisir
Date: 2015-07-11 22:17:41.000000000
Message: 
Patch Set 1:

Allow me to disagree. If we use Hudson as the only reference on which tests should run, then over time the tests will only run on Hudson. Which is the situation we are in now. It becomes harder and harder to run tests locally or on other setups.

Also, Hudson uses a specific configuration (GTK2 + metacity WM), which is very different than the usual default configuration of our Linux users (GTK3 + compiz/gnome-shell/kde4 etc.) Why are we giving so much importance to tests that are not technically representative and useful?

There are plenty of other tests in the tree, including SWTBot tests, that can survive being run 100+ times in a row, with https://git.eclipse.org/r/#/c/51779/ for example. There is something wrong with these tests if they fail once in a while, so this means we can and should fix them.

Perhaps we should setup a "stress tests" job on Hudson too?
----------------------------------------------------------------------------------------------------------------------
Author: Marc-André Laperle
Date: 2015-07-12 02:53:08.000000000
Message: 
Patch Set 1:

> If we use Hudson as the only reference on
 > which tests should run

That's not what I am suggesting. We can have other "references". We will have a Windows and Mac slave running in the next few days too (we had our first test build this week). Your help is also appreciated for other Ubuntu versions and window managers, etc. Fixes are always welcome for other setups.

What would determine the acceptability of a test to you? That it runs on all possible configurations out there? That's not very sustainable. We also have no idea if the issues are in our code or buggy libraries. I think so far, the unwritten rule have been something like:
- The test has to run on the machine of the person sending the patch
- The test has to run on the machine of the person reviewing the patch
- The test has to run on Hudson's Gerrit and master jobs

What would be the criteria that you are suggesting? Maybe also all the "supported" platforms according to their own maintainers, so:
- The test has to run on the machine of the person sending the patch
- The test has to run on the machine of the person reviewing the patch
- The test has to run on Hudson's Gerrit job
- It has to run on Ubuntu LTS 12.04, GTK3.4, GTK2, metacity, compiz, kde
- Ubuntu LTS 14.04 GTK3.10, GTK2, metacity, compiz, kde
- Ubuntu LTS 15.10 GTK3.16, GTK2, metacity, compiz, kde
- OSX 10.9
- OSX 10.10
- Windows Vista
- Windows 7
- Windows 8.1
- Windows 10
- Debian
- Red Hat
- ... and so on

We clearly don't have the infrastructure for this, especially at eclipse.org. What we can do though, is say that the tests have to pass on Hudson then it's a best effort to make the other setup work. That's what we have been doing so far (I have jenkins for Ubuntu 14.04, 15.04 and Windows), but now we can increase the setup coverage with more and more CI (Efficios!).

 > Also, Hudson uses a specific configuration (GTK2 + metacity WM),
 > which is very different than the usual default configuration of our
 > Linux users (GTK3 + compiz/gnome-shell/kde4 etc.) Why are we giving
 > so much importance to tests that are not technically representative
 > and useful?

Because that's the Hudson build that tests regressions for contributions. If we know a test works for that configuration and someone pushes a patch that breaks it, we know for sure it's a regression. Sure we don't know if it works for other configurations but we'll know when it breaks that configuration, and that's already a big plus compared to not knowing at all.

I agree completely that the Hudson configuration could be more representative of the user base and we could ask the webmasters about that. I would be 100% behind that. Although... I think most of users are actually on Windows :p

 > There are plenty of other tests in the tree, including SWTBot
 > tests, that can survive being run 100+ times in a row, with
 > https://git.eclipse.org/r/#/c/51779/ for example. There is
 > something wrong with these tests if they fail once in a while, so
 > this means we can and should fix them.

I don't dispute that. I will help fixing them too. As I have in the past on Mac, Windows and Ubuntu versions. Ignoring the tests might just make people forget about them too..

 > Perhaps we should setup a "stress tests" job on Hudson too?

Maybe, not sure if we are allowed to use that much cpu time though. Something to look into.
----------------------------------------------------------------------------------------------------------------------
Author: Marc-André Laperle
Date: 2015-07-12 02:54:41.000000000
Message: 
Patch Set 1:

> - Ubuntu LTS 15.10 GTK3.16, GTK2, metacity, compiz, kde

I meant Ubuntu 15.04 here, too much copy paste!
----------------------------------------------------------------------------------------------------------------------
Author: Alexandre Montplaisir
Date: 2015-07-12 03:41:04.000000000
Message: 
Patch Set 1:

> Although... I think most of users are actually on Windows :p

Our Hudson tests are even less representative then! :P

I completely agree that @Ignore and forget is not the good solution. I'd be happy with not actually merging this patch, but instead fixing the tests within a reasonable delay so that they can run reliably.

But having flaky tests in the tree is very detrimental. It makes testing locally very painful. It can also hide legit problems because people are too used to clicking Retrigger every time they get a failure ( https://git.eclipse.org/r/#/c/50310/5 comes to mind). The goal of having tests is to catch problems early rather than late, so you save time overall. However, if you waste more time dealing with the downsides of flaky tests, perhaps the trade-off is not that good.

Perhaps we should start with identifying which tests are flaky on Hudson. A lightweight stress-test job would help with that. Then work on fixing those. Then we could slowly expand the definition to other "reasonable" platforms. That could mean any Windows, Mac, Ubuntu with more or less default settings, but maybe not a Gentoo all compiled with -03 --funroll-loops...

Once we have all those multi-platform CI jobs set up, it should become very easy to identify spuriously failing tests. Then we either deal with them, or @Ignore/revert them out until someone has time to look into. As long as we don't just let flaky tests linger in the tree and make everyone's lives miserable.
----------------------------------------------------------------------------------------------------------------------
