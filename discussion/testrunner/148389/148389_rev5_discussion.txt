======================================================================================================================
DESCRIPTION:

CBQE-6226: Cluster setup as per ini in install script

Change-Id: I46a4702555c1704923d5a229526dcf1656989cc1

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Jake Rawsthorne
Date: 2021-03-16 16:35:48.000000000
Message: 
Uploaded patch set 5.
----------------------------------------------------------------------------------------------------------------------
Author:  Pavithra Mahamani
Date: 2021-03-16 17:25:32.000000000
Message: 
Patch Set 5:

(2 comments)
Line:78, scripts/new_install.py -> lets move this check to init_clusters()..maybe add couple of retries if the check fails.

Line:96, scripts/new_install.py -> Can we print: "cluster:{0}\tnode:{1}\tversion:{1}\taFamily:{3}\tservices:{4}"? That way you can use the same print for single node and multinode clusters.

----------------------------------------------------------------------------------------------------------------------
Author:  Pavithra Mahamani
Date: 2021-03-16 17:49:47.000000000
Message: 
Patch Set 5:

(1 comment)
Line:828, scripts/install_utils.py -> Can we use the existing add_node() in rest_client.py instead of doing rebalance? It has good exception handling.

----------------------------------------------------------------------------------------------------------------------
Author:  Pavithra Mahamani
Date: 2021-03-16 17:57:59.000000000
Message: 
Patch Set 5:

(1 comment)
Line:828, scripts/install_utils.py -> Actually, I dont see add_node() being used anywhere, so cluster.async_rebalance() might be better.

----------------------------------------------------------------------------------------------------------------------
Author: Jake Rawsthorne
Date: 2021-03-19 16:00:29.000000000
Message: 
Patch Set 5:

What should be done about memory quotas. Currently the cluster quotas are set based on the first node in the cluster. E.g. if node1 has kv,fts and node2 has kv then the quota for kv will subtract 256mb for fts. If node1 and node2 are switched the fts quota is not subtracted and each node in the cluster will potentially be oversized. Is this a problem that needs to be addresed? I don't know what test owners currently do 

One solution is: find node with least mem and subtract reserve and 0.67 ratio defined in CLUSTER_QUOTA_RATIO, collect all services used in cluster, subtract memory for each service and set, left over set for kv
----------------------------------------------------------------------------------------------------------------------
Author: Jake Rawsthorne
Date: 2021-04-07 15:13:51.000000000
MISMATCHED INLINE COMMENT
Line:96, scripts/new_install.py -> Done
----------------------------------------------------------------------------------------------------------------------
