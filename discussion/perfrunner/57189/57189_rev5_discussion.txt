======================================================================================================================
DESCRIPTION:

new backup wrapper tests:

tests covered based on "Test Scenario for Enterprise Backup Restore" doc:
https://docs.google.com/spreadsheets/d/1JWyj58QVm2FOeDB9GGYvFw6t1VpenI13lY5Nd4CPt9o/edit#gid=26013390

Change-Id: Icb8fb5d756883600056a94cf791000c13139dc81

======================================================================================================================
COMMENTS
======================================================================================================================
Author: Andrei Baranouski
Date: 2015-11-25 20:23:03.000000000
Message: 
Uploaded patch set 5.
----------------------------------------------------------------------------------------------------------------------
Author: Mike Wiederhold
Date: 2015-12-02 02:39:25.000000000
Message: 
Patch Set 5:

(13 comments)
Line:9, tests/backup_60M_folder_size_CE.test -> mem_quota = 52428

Line:10, tests/backup_60M_folder_size_CE.test -> initial_nodes = 4

Line:1, tests/backup_60M_incr_workload_CE.test -> In this test case we want to load 60M items, backup the data, then load 100k new items and do 1M updates. Then we want to stop the load and backup again. This test case appears to have background mutations while there is a backup going on. The problem with this is that different test runs will end up backing up different amounts of data making it difficult to compare between runs.

Line:9, tests/backup_60M_incr_workload_CE.test -> mem_quota = 52428

Line:10, tests/backup_60M_incr_workload_CE.test -> initial_nodes = 4

Line:9, tests/backup_60M_workload_CE.test -> mem_quota = 52428

Line:10, tests/backup_60M_workload_CE.test -> initial_nodes = 4

Line:26, tests/backup_60M_workload_CE.test -> throughput = 15000

Line:9, tests/restore_60M_CE.test -> mem_quota = 52428

Line:10, tests/restore_60M_CE.test -> initial_nodes = 4

Line:1, tests/restore_after_incr_backup_60M_workload_CE.test -> I'm not sure that this is going to do what we want since the access phase is running during the entire backup and restore process. What we want is to load 60M items. Back them up. Then load 100K items and update 1M items, stop the load, and backup up again. Then we want to delete all of the data in the cluster and restore the incremental backup.

Line:9, tests/restore_after_incr_backup_60M_workload_CE.test -> mem_quota = 52428

Line:10, tests/restore_after_incr_backup_60M_workload_CE.test -> initial_nodes = 4

----------------------------------------------------------------------------------------------------------------------
Author: Gerrit Code Review
Date: 2015-12-03 20:15:32.000000000
Message: 
The change could not be merged due to a path conflict.

Please rebase the change locally and upload the rebased commit for review.
----------------------------------------------------------------------------------------------------------------------
Author: Gerrit Code Review
Date: 2015-12-03 20:16:59.000000000
Message: 
Change has been successfully cherry-picked as 64adb6c60edfbefb08aed0a8c2d7418e160f0eee
----------------------------------------------------------------------------------------------------------------------
